<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AIèµ„è®¯æ—¥æŠ¥ - 2025/7/29</title>
  <style>
    /* æ·»åŠ æŒ‰é’®æ ·å¼ */
    .nav-buttons {
      display: flex;
      gap: 15px;
      justify-content: center;
      margin-top: 15px;
      flex-wrap: wrap;
    }
    .nav-button {
      background: rgba(255, 255, 255, 0.2);
      border: 1px solid rgba(255, 255, 255, 0.4);
      border-radius: 20px;
      padding: 6px 15px;
      color: white;
      text-decoration: none;
      display: inline-flex;
      align-items: center;
      transition: all 0.3s;
      font-size: 0.9em;
    }
    .nav-button:hover {
      background: rgba(255, 255, 255, 0.3);
      transform: translateY(-2px);
    }
    /* å…¶ä»–æ ·å¼ä¿æŒä¸å˜ */
    body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background: #f5f5f5; color: #333; margin: 0; padding: 0; }
    .container { max-width: 1200px; margin: auto; padding: 20px; }
    .header { background: linear-gradient(135deg, #667eea, #764ba2); color: #fff; padding: 40px 20px; border-radius: 10px; text-align: center; }
    .header h1 { font-size: 2.5em; margin: 0; }
    .summary, .history-section { background: #fff; margin-top: 30px; padding: 25px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
    .summary h2, .history-section h2 { color: #667eea; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 15px; }
    .news-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(350px, 1fr)); gap: 20px; margin-top: 30px; }
    .news-item { background: white; border-radius: 10px; padding: 20px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
    .news-item h3 a { text-decoration: none; color: #333; font-size: 1.1em; }
    .news-item h3 a:hover { color: #667eea; }
    .news-meta { font-size: 0.9em; color: #666; margin-bottom: 10px; }
    .category { display: inline-block; padding: 4px 10px; border-radius: 20px; font-size: 0.8em; margin-right: 8px; }
    .category.industry { background: #e3f2fd; color: #1976d2; }
    .category.academic { background: #f3e5f5; color: #7b1fa2; }
    .category.opensource { background: #e8f5e9; color: #388e3c; }
    .summary-text { margin-top: 10px; color: #555; }
    .importance { background: #ff9800; color: white; padding: 2px 8px; border-radius: 10px; font-size: 0.75em; margin-left: 10px; }
    .history-list { list-style: none; padding-left: 0; }
    .history-list li { margin: 5px 0; }
    .history-list a { text-decoration: none; color: #333; }
    .history-list a:hover { color: #667eea; }
    .footer { text-align: center; font-size: 0.9em; color: #999; padding: 20px; margin-top: 40px; }
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>ğŸ¤– AIèµ„è®¯æ—¥æŠ¥</h1>
      <p>2025/7/29 | äººå·¥æ™ºèƒ½é¢†åŸŸæœ€æ–°åŠ¨æ€</p>
      <div class="nav-buttons">
        <a href="../daily/2025-07-28.html" class="nav-button">
          ğŸ”™ æŸ¥çœ‹æ˜¨æ—¥å†…å®¹
        </a>
        <a href="../" class="nav-button">
          ğŸ  è¿”å›ä¸»é¡µ
        </a>
      </div>
    </div>

    <div class="summary">
      <h2>ğŸ“Š ä»Šæ—¥è¶‹åŠ¿æ€»ç»“</h2>
      <p>AIé¢†åŸŸæŒç»­å¿«é€Ÿå‘å±•ï¼Œæ¶‰åŠè¡Œä¸šåº”ç”¨ã€æŠ€æœ¯æŒ‘æˆ˜ã€æ³•å¾‹è§„èŒƒåŠäººæ‰åŸ¹å…»ç­‰å¤šæ–¹é¢ã€‚ä»æŠ€æœ¯è®¨è®ºåˆ°å®é™…åº”ç”¨ï¼Œæ˜¾ç¤ºå‡ºAIæŠ€æœ¯çš„å¹¿æ³›å½±å“å’Œæ½œåŠ›ã€‚</p>
    </div>

    <div class="news-grid">
      
        <div class="news-item">
          <h3><a href="http://www.yourobot.io/blog/uncategorized/the-next-bill-gates-or-albert-einstein-in-ai-artificial-intelligence-will-produce-the-god-algorithm-of-machine-learning-where-a-machine-will-be-able-to-do-and-learn-anything-by-its-self/" target="_blank">The Next Bill Gates or Albert Einstein in AI â€œChris Clarkâ€ â€“ Yourobot</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 9</span>
          </div>
          <div class="summary-text">AIé¢†åŸŸçš„ä¸‹ä¸€ä¸ªæ¯”å°”Â·ç›–èŒ¨æˆ–çˆ±å› æ–¯å¦</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=36233487" target="_blank">Ask HN: Is the rate of progress in AI exponential?</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 8</span>
          </div>
          <div class="summary-text">æ¢è®¨AIè¿›æ­¥é€Ÿåº¦æ˜¯å¦å‘ˆæŒ‡æ•°çº§å¢é•¿</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=18049136" target="_blank">50% Cheaper GPUs for cloud-computing / Saving devs 50% compared to AWS</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 8</span>
          </div>
          <div class="summary-text">äº‘è®¡ç®—GPUæˆæœ¬é™ä½50%ï¼Œç›¸æ¯”AWSèŠ‚çœå¼€å‘è€…50%</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=27111719" target="_blank">Ask HN: What's the pain using current AI algorithms?</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 7</span>
          </div>
          <div class="summary-text">æ¢è®¨å½“å‰AIç®—æ³•çš„ç—›ç‚¹</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://lekta.ai/blog/natural-language-processing-artificial-intelligence-machine-learning-bots-a-passing-trend-or-much-more" target="_blank">NLP, AI, ML, bots â€“ a passing trend or much more? What's your take on this?</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 7</span>
          </div>
          <div class="summary-text">NLPã€AIã€MLã€æœºå™¨äººæ˜¯çŸ­æš‚è¶‹åŠ¿è¿˜æ˜¯æ›´å¤šï¼Ÿ</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=401541" target="_blank">Common Lisp + Machine Learning Internship at Google (Mountain View, CA)</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 6</span>
          </div>
          <div class="summary-text">è°·æ­Œæä¾›Common Lispä¸æœºå™¨å­¦ä¹ å®ä¹ æœºä¼š</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=12995049" target="_blank">Ask HN: Dipping my toes with artificial intelligence and what to expect? (CS)</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 6</span>
          </div>
          <div class="summary-text">åˆæ¢äººå·¥æ™ºèƒ½åŠå…¶é¢„æœŸ</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=35103021" target="_blank">The AI Crackpot Index</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">AIé¢†åŸŸçš„ç–¯ç‹‚æŒ‡æ•°è®¨è®º</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=244100" target="_blank">Ask HN: Thoughts on grad school? (CS PhD)</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">å…³äºç ”ç©¶ç”Ÿé™¢çš„æ€è€ƒï¼ˆCSåšå£«ï¼‰</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=36431356" target="_blank">Ask HN: Anyone concerned about NYC Local Law 144?</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 4</span>
          </div>
          <div class="summary-text">è®¨è®ºå¯¹çº½çº¦å¸‚åœ°æ–¹æ³•å¾‹144çš„å…³æ³¨</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=42619160" target="_blank">Show HN: Startup Raising capital through Book Sales</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 3</span>
          </div>
          <div class="summary-text">åˆåˆ›å…¬å¸é€šè¿‡ä¹¦ç±é”€å”®ç­¹é›†èµ„é‡‘</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=15140715" target="_blank">Bioinformatician</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 2</span>
          </div>
          <div class="summary-text">ç”Ÿç‰©ä¿¡æ¯å­¦å®¶çš„è®¨è®º</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.21046v1" target="_blank">A Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 10</span>
          </div>
          <div class="summary-text">ç»¼è¿°è‡ªè¿›åŒ–ä»£ç†ï¼Œè¿ˆå‘äººå·¥è¶…çº§æ™ºèƒ½çš„é“è·¯ã€‚</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">ğŸ‘¨â€ğŸ”¬ Huan-ang Gao, Jiayi Geng, Wenyue Hua, Mengkang Hu, Xinzhe Juan, Hongzhang Liu, Shilong Liu, Jiahao Qiu, Xuan Qi, Yiran Wu, Hongru Wang, Han Xiao, Yuhang Zhou, Shaokun Zhang, Jiayi Zhang, Jinyu Xiang, Yixiong Fang, Qiwen Zhao, Dongrui Liu, Qihan Ren, Cheng Qian, Zhenghailong Wang, Minda Hu, Huazheng Wang, Qingyun Wu, Heng Ji, Mengdi Wang</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.21035v1" target="_blank">GenoMAS: A Multi-Agent Framework for Scientific Discovery via Code-Driven Gene Expression Analysis</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 9</span>
          </div>
          <div class="summary-text">GenoMASï¼šé€šè¿‡ä»£ç é©±åŠ¨çš„åŸºå› è¡¨è¾¾åˆ†æè¿›è¡Œç§‘å­¦å‘ç°çš„å¤šä»£ç†æ¡†æ¶ã€‚</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">ğŸ‘¨â€ğŸ”¬ Haoyang Liu, Yijiang Li, Haohan Wang</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.21004v1" target="_blank">Compositional Function Networks: A High-Performance Alternative to Deep Neural Networks with Built-in Interpretability</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 9</span>
          </div>
          <div class="summary-text">Deep Neural Networks (DNNs) deliver impressive performance but their
black-box nature limits deployment in high-stakes domains requiring
transparency. We introduce Compositional Function Networks (CFNs), a novel
framework that builds inherently interpretable models by composing elementary
mathematical functions with clear semantics. Unlike existing interpretable
approaches that are limited to simple additive structures, CFNs support diverse
compositional patterns -- sequential, parallel, and conditional -- enabling
complex feature interactions while maintaining transparency. A key innovation
is that CFNs are fully differentiable, allowing efficient training through
standard gradient descent. We demonstrate CFNs' versatility across multiple
domains, from symbolic regression to image classification with deep
hierarchical networks. Our empirical evaluation shows CFNs achieve competitive
performance against black-box models (96.24% accuracy on CIFAR-10) while
outperforming state-of-the-art interpretable models like Explainable Boosting
Machines. By combining the hierarchical expressiveness and efficient training
of deep learning with the intrinsic interpretability of well-defined
mathematical functions, CFNs offer a powerful framework for applications where
both performance and accountability are paramount.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">ğŸ‘¨â€ğŸ”¬ Fang Li</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.20984v1" target="_blank">SmallThinker: A Family of Efficient Large Language Models Natively Trained for Local Deployment</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 9</span>
          </div>
          <div class="summary-text">While frontier large language models (LLMs) continue to push capability
boundaries, their deployment remains confined to GPU-powered cloud
infrastructure. We challenge this paradigm with SmallThinker, a family of LLMs
natively designed - not adapted - for the unique constraints of local devices:
weak computational power, limited memory, and slow storage. Unlike traditional
approaches that mainly compress existing models built for clouds, we architect
SmallThinker from the ground up to thrive within these limitations. Our
innovation lies in a deployment-aware architecture that transforms constraints
into design principles. First, We introduce a two-level sparse structure
combining fine-grained Mixture-of-Experts (MoE) with sparse feed-forward
networks, drastically reducing computational demands without sacrificing model
capacity. Second, to conquer the I/O bottleneck of slow storage, we design a
pre-attention router that enables our co-designed inference engine to prefetch
expert parameters from storage while computing attention, effectively hiding
storage latency that would otherwise cripple on-device inference. Third, for
memory efficiency, we utilize NoPE-RoPE hybrid sparse attention mechanism to
slash KV cache requirements. We release SmallThinker-4B-A0.6B and
SmallThinker-21B-A3B, which achieve state-of-the-art performance scores and
even outperform larger LLMs. Remarkably, our co-designed system mostly
eliminates the need for expensive GPU hardware: with Q4_0 quantization, both
models exceed 20 tokens/s on ordinary consumer CPUs, while consuming only 1GB
and 8GB of memory respectively. SmallThinker is publicly available at
hf.co/PowerInfer/SmallThinker-4BA0.6B-Instruct and
hf.co/PowerInfer/SmallThinker-21BA3B-Instruct.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">ğŸ‘¨â€ğŸ”¬ Yixin Song, Zhenliang Xue, Dongliang Wei, Feiyang Chen, Jianxiang Gao, Junchen Liu, Hangyu Liang, Guangshuo Qin, Chengrong Tian, Bo Wen, Longyu Zhao, Xinrui Zheng, Zeyu Mi, Haibo Chen</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.21017v1" target="_blank">MIRAGE-Bench: LLM Agent is Hallucinating and Where to Find Them</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 8</span>
          </div>
          <div class="summary-text">MIRAGE-Benchï¼šLLMä»£ç†çš„å¹»è§‰åŠå…¶å‘ç°ä½ç½®ã€‚</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">ğŸ‘¨â€ğŸ”¬ Weichen Zhang, Yiyou Sun, Pohao Huang, Jiayue Pu, Heyue Lin, Dawn Song</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.20997v1" target="_blank">Modular Delta Merging with Orthogonal Constraints: A Scalable Framework for Continual and Reversible Model Composition</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 8</span>
          </div>
          <div class="summary-text">In real-world machine learning deployments, models must be continually
updated, composed, and when required, selectively undone. However, existing
approaches to model merging and continual learning often suffer from task
interference, catastrophic forgetting, or lack of reversibility. We propose
Modular Delta Merging with Orthogonal Constraints (MDM-OC), a novel framework
that enables scalable, interference-free, and reversible composition of
fine-tuned models. Each task-specific model is encoded as a delta from a shared
base and projected into an orthogonal subspace to eliminate conflict. These
projected deltas are then merged via gradient-based optimization to form a
unified model that retains performance across tasks. Our approach supports
continual integration of new models, structured unmerging for compliance such
as GDPR requirements, and model stability via elastic weight consolidation and
synthetic replay. Extensive experiments on vision and natural language
processing benchmarks demonstrate that MDM-OC outperforms prior baselines in
accuracy, backward transfer, and unmerge fidelity, while remaining
memory-efficient and computationally tractable. This framework offers a
principled solution for modular and compliant AI system design.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">ğŸ‘¨â€ğŸ”¬ Haris Khan, Shumaila Asif, Sadia Asif</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.20994v1" target="_blank">Security Tensors as a Cross-Modal Bridge: Extending Text-Aligned Safety to Vision in LVLM</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 8</span>
          </div>
          <div class="summary-text">Large visual-language models (LVLMs) integrate aligned large language models
(LLMs) with visual modules to process multimodal inputs. However, the safety
mechanisms developed for text-based LLMs do not naturally extend to visual
modalities, leaving LVLMs vulnerable to harmful image inputs. To address this
cross-modal safety gap, we introduce security tensors - trainable input vectors
applied during inference through either the textual or visual modality. These
tensors transfer textual safety alignment to visual processing without
modifying the model's parameters. They are optimized using a curated dataset
containing (i) malicious image-text pairs requiring rejection, (ii) contrastive
benign pairs with text structurally similar to malicious queries, with the
purpose of being contrastive examples to guide visual reliance, and (iii)
general benign samples preserving model functionality. Experimental results
demonstrate that both textual and visual security tensors significantly enhance
LVLMs' ability to reject diverse harmful visual inputs while maintaining
near-identical performance on benign tasks. Further internal analysis towards
hidden-layer representations reveals that security tensors successfully
activate the language module's textual "safety layers" in visual inputs,
thereby effectively extending text-based safety to the visual modality.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">ğŸ‘¨â€ğŸ”¬ Shen Li, Liuyi Yao, Wujia Niu, Lan Zhang, Yaliang Li</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.21027v1" target="_blank">Smart Expansion Techniques for ASP-based Interactive Configuration</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 7</span>
          </div>
          <div class="summary-text">åŸºäºASPçš„äº¤äº’å¼é…ç½®çš„æ™ºèƒ½æ‰©å±•æŠ€æœ¯ã€‚</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">ğŸ‘¨â€ğŸ”¬ Lucia BalÃ¡Å¾ovÃ¡, Richard Comploi-Taupe, Susana Hahn, Nicolas RÃ¼hling, Gottfried Schenner</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.21009v1" target="_blank">Memorization in Fine-Tuned Large Language Models</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 7</span>
          </div>
          <div class="summary-text">This study investigates the mechanisms and factors influencing memorization
in fine-tuned large language models (LLMs), with a focus on the medical domain
due to its privacy-sensitive nature. We examine how different aspects of the
fine-tuning process affect a model's propensity to memorize training data,
using the PHEE dataset of pharmacovigilance events. Our research employs two main approaches: a membership inference attack to
detect memorized data, and a generation task with prompted prefixes to assess
verbatim reproduction. We analyze the impact of adapting different weight
matrices in the transformer architecture, the relationship between perplexity
and memorization, and the effect of increasing the rank in low-rank adaptation
(LoRA) fine-tuning. Key findings include: (1) Value and Output matrices contribute more
significantly to memorization compared to Query and Key matrices; (2) Lower
perplexity in the fine-tuned model correlates with increased memorization; (3)
Higher LoRA ranks lead to increased memorization, but with diminishing returns
at higher ranks. These results provide insights into the trade-offs between model performance
and privacy risks in fine-tuned LLMs. Our findings have implications for
developing more effective and responsible strategies for adapting large
language models while managing data privacy concerns.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">ğŸ‘¨â€ğŸ”¬ Danil Savine, Muni Sreenivas Pydi, Jamal Atif, Olivier CappÃ©</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.20993v1" target="_blank">Personalized Treatment Effect Estimation from Unstructured Data</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 7</span>
          </div>
          <div class="summary-text">Existing methods for estimating personalized treatment effects typically rely
on structured covariates, limiting their applicability to unstructured data.
Yet, leveraging unstructured data for causal inference has considerable
application potential, for instance in healthcare, where clinical notes or
medical images are abundant. To this end, we first introduce an approximate
'plug-in' method trained directly on the neural representations of unstructured
data. However, when these fail to capture all confounding information, the
method may be subject to confounding bias. We therefore introduce two
theoretically grounded estimators that leverage structured measurements of the
confounders during training, but allow estimating personalized treatment
effects purely from unstructured inputs, while avoiding confounding bias. When
these structured measurements are only available for a non-representative
subset of the data, these estimators may suffer from sampling bias. To address
this, we further introduce a regression-based correction that accounts for the
non-uniform sampling, assuming the sampling mechanism is known or can be
well-estimated. Our experiments on two benchmark datasets show that the plug-in
method, directly trainable on large unstructured datasets, achieves strong
empirical performance across all settings, despite its simplicity.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">ğŸ‘¨â€ğŸ”¬ Henri Arno, Thomas Demeester</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.20968v1" target="_blank">From Entanglement to Alignment: Representation Space Decomposition for Unsupervised Time Series Domain Adaptation</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 7</span>
          </div>
          <div class="summary-text">Domain shift poses a fundamental challenge in time series analysis, where
models trained on source domain often fail dramatically when applied in target
domain with different yet similar distributions. While current unsupervised
domain adaptation (UDA) methods attempt to align cross-domain feature
distributions, they typically treat features as indivisible entities, ignoring
their intrinsic compositions that governs domain adaptation. We introduce
DARSD, a novel UDA framework with theoretical explainability that explicitly
realizes UDA tasks from the perspective of representation space decomposition.
Our core insight is that effective domain adaptation requires not just
alignment, but principled disentanglement of transferable knowledge from mixed
representations. DARSD consists three synergistic components: (I) An
adversarial learnable common invariant basis that projects original features
into a domain-invariant subspace while preserving semantic content; (II) A
prototypical pseudo-labeling mechanism that dynamically separates target
features based on confidence, hindering error accumulation; (III) A hybrid
contrastive optimization strategy that simultaneously enforces feature
clustering and consistency while mitigating emerging distribution gaps.
Comprehensive experiments conducted on four benchmark datasets (WISDM, HAR,
HHAR, and MFD) demonstrate DARSD's superiority against 12 UDA algorithms,
achieving optimal performance in 35 out of 53 cross-domain scenarios.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">ğŸ‘¨â€ğŸ”¬ Rongyao Cai, Ming Jin, Qingsong Wen, Kexin Zhang</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.20987v1" target="_blank">JWB-DH-V1: Benchmark for Joint Whole-Body Talking Avatar and Speech Generation Version 1</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 6</span>
          </div>
          <div class="summary-text">Recent advances in diffusion-based video generation have enabled
photo-realistic short clips, but current methods still struggle to achieve
multi-modal consistency when jointly generating whole-body motion and natural
speech. Current approaches lack comprehensive evaluation frameworks that assess
both visual and audio quality, and there are insufficient benchmarks for
region-specific performance analysis. To address these gaps, we introduce the
Joint Whole-Body Talking Avatar and Speech Generation Version I(JWB-DH-V1),
comprising a large-scale multi-modal dataset with 10,000 unique identities
across 2 million video samples, and an evaluation protocol for assessing joint
audio-video generation of whole-body animatable avatars. Our evaluation of SOTA
models reveals consistent performance disparities between face/hand-centric and
whole-body performance, which incidates essential areas for future research.
The dataset and evaluation tools are publicly available at
https://github.com/deepreasonings/WholeBodyBenchmark.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">ğŸ‘¨â€ğŸ”¬ Xinhan Di, Kristin Qi, Pengqian Yu</div>
        </div>
      
    </div>

    <div class="history-section">
        <h2>ğŸ“… å†å²æ—¥æŠ¥ç›®å½•</h2>
        <ul class="history-list">
          <li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-27.html" target="_blank">2025-07-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-26.html" target="_blank">2025-07-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-25.html" target="_blank">2025-07-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-24.html" target="_blank">2025-07-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-23.html" target="_blank">2025-07-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-22.html" target="_blank">2025-07-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-21.html" target="_blank">2025-07-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-20.html" target="_blank">2025-07-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-19.html" target="_blank">2025-07-19</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-18.html" target="_blank">2025-07-18</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-17.html" target="_blank">2025-07-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-16.html" target="_blank">2025-07-16</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-15.html" target="_blank">2025-07-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-13.html" target="_blank">2025-07-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-12.html" target="_blank">2025-07-12</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-11.html" target="_blank">2025-07-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-10.html" target="_blank">2025-07-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-09.html" target="_blank">2025-07-09</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-08.html" target="_blank">2025-07-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-07.html" target="_blank">2025-07-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-06.html" target="_blank">2025-07-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-05.html" target="_blank">2025-07-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-04.html" target="_blank">2025-07-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-03.html" target="_blank">2025-07-03</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-02.html" target="_blank">2025-07-02</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-01.html" target="_blank">2025-07-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-30.html" target="_blank">2025-06-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-29.html" target="_blank">2025-06-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-28.html" target="_blank">2025-06-28</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-27.html" target="_blank">2025-06-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-26.html" target="_blank">2025-06-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-25.html" target="_blank">2025-06-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-24.html" target="_blank">2025-06-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-23.html" target="_blank">2025-06-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-22.html" target="_blank">2025-06-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-21.html" target="_blank">2025-06-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-20.html" target="_blank">2025-06-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-19.html" target="_blank">2025-06-19</a></li>
        </ul>
      </div>

    <div class="footer">
      ğŸ”„ ç”± Cloudflare Workers + DeepSeek è‡ªåŠ¨ç”Ÿæˆ | æ›´æ–°æ—¶é—´: 2025/7/29 22:02:30
    </div>
  </div>
</body>
</html>