<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI资讯日报 - 2025/8/2</title>
  <style>
    /* 添加按钮样式 */
    .nav-buttons {
      display: flex;
      gap: 15px;
      justify-content: center;
      margin-top: 15px;
      flex-wrap: wrap;
    }
    .nav-button {
      background: rgba(255, 255, 255, 0.2);
      border: 1px solid rgba(255, 255, 255, 0.4);
      border-radius: 20px;
      padding: 6px 15px;
      color: white;
      text-decoration: none;
      display: inline-flex;
      align-items: center;
      transition: all 0.3s;
      font-size: 0.9em;
    }
    .nav-button:hover {
      background: rgba(255, 255, 255, 0.3);
      transform: translateY(-2px);
    }
    /* 其他样式保持不变 */
    body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background: #f5f5f5; color: #333; margin: 0; padding: 0; }
    .container { max-width: 1200px; margin: auto; padding: 20px; }
    .header { background: linear-gradient(135deg, #667eea, #764ba2); color: #fff; padding: 40px 20px; border-radius: 10px; text-align: center; }
    .header h1 { font-size: 2.5em; margin: 0; }
    .summary, .history-section { background: #fff; margin-top: 30px; padding: 25px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
    .summary h2, .history-section h2 { color: #667eea; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 15px; }
    .news-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(350px, 1fr)); gap: 20px; margin-top: 30px; }
    .news-item { background: white; border-radius: 10px; padding: 20px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
    .news-item h3 a { text-decoration: none; color: #333; font-size: 1.1em; }
    .news-item h3 a:hover { color: #667eea; }
    .news-meta { font-size: 0.9em; color: #666; margin-bottom: 10px; }
    .category { display: inline-block; padding: 4px 10px; border-radius: 20px; font-size: 0.8em; margin-right: 8px; }
    .category.industry { background: #e3f2fd; color: #1976d2; }
    .category.academic { background: #f3e5f5; color: #7b1fa2; }
    .category.opensource { background: #e8f5e9; color: #388e3c; }
    .summary-text { margin-top: 10px; color: #555; }
    .importance { background: #ff9800; color: white; padding: 2px 8px; border-radius: 10px; font-size: 0.75em; margin-left: 10px; }
    .history-list { list-style: none; padding-left: 0; }
    .history-list li { margin: 5px 0; }
    .history-list a { text-decoration: none; color: #333; }
    .history-list a:hover { color: #667eea; }
    .footer { text-align: center; font-size: 0.9em; color: #999; padding: 20px; margin-top: 40px; }
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>🤖 AI资讯日报</h1>
      <p>2025/8/2 | 人工智能领域最新动态</p>
      <div class="nav-buttons">
        <a href="../daily/2025-08-01.html" class="nav-button">
          🔙 查看昨日内容
        </a>
        <a href="../" class="nav-button">
          🏠 返回主页
        </a>
      </div>
    </div>

    <div class="summary">
      <h2>📊 今日趋势总结</h2>
      <p>AI领域持续快速发展，涵盖了从理论研究到实际应用的广泛话题。当前趋势显示，行业内部对AI算法的实际应用痛点、技术进步速度、以及法律和伦理问题表现出浓厚兴趣。同时，AI教育和职业机会，如实习和研究生教育，也受到关注。技术创新，如更经济的GPU解决方案，以及AI在生物信息学等领域的应用，预示着AI技术的广泛应用前景。</p>
    </div>

    <div class="news-grid">
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=27111719" target="_blank">Ask HN: What's the pain using current AI algorithms?</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 9</span>
          </div>
          <div class="summary-text">探讨当前AI算法使用中的痛点。</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=36233487" target="_blank">Ask HN: Is the rate of progress in AI exponential?</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 8</span>
          </div>
          <div class="summary-text">讨论AI进步速度是否呈指数级增长。</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=36431356" target="_blank">Ask HN: Anyone concerned about NYC Local Law 144?</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 7</span>
          </div>
          <div class="summary-text">询问对纽约市地方法律144的担忧。</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://lekta.ai/blog/natural-language-processing-artificial-intelligence-machine-learning-bots-a-passing-trend-or-much-more" target="_blank">NLP, AI, ML, bots – a passing trend or much more? What's your take on this?</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 7</span>
          </div>
          <div class="summary-text">探讨NLP、AI、ML和机器人是短暂趋势还是更深远的变革。</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=401541" target="_blank">Common Lisp + Machine Learning Internship at Google (Mountain View, CA)</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 6</span>
          </div>
          <div class="summary-text">谷歌提供Common Lisp和机器学习实习机会。</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=18049136" target="_blank">50% Cheaper GPUs for cloud-computing / Saving devs 50% compared to AWS</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 6</span>
          </div>
          <div class="summary-text">提供比AWS便宜50%的GPU云计算解决方案。</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://www.yourobot.io/blog/uncategorized/the-next-bill-gates-or-albert-einstein-in-ai-artificial-intelligence-will-produce-the-god-algorithm-of-machine-learning-where-a-machine-will-be-able-to-do-and-learn-anything-by-its-self/" target="_blank">The Next Bill Gates or Albert Einstein in AI “Chris Clark” – Yourobot</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 5</span>
          </div>
          <div class="summary-text">介绍AI领域的潜在领军人物Chris Clark。</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=15140715" target="_blank">Bioinformatician</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 5</span>
          </div>
          <div class="summary-text">生物信息学家的职业机会。</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=12995049" target="_blank">Ask HN: Dipping my toes with artificial intelligence and what to expect? (CS)</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 4</span>
          </div>
          <div class="summary-text">初学者询问涉足AI领域的预期。</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=244100" target="_blank">Ask HN: Thoughts on grad school? (CS PhD)</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 4</span>
          </div>
          <div class="summary-text">讨论计算机科学研究生教育的看法。</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=35103021" target="_blank">The AI Crackpot Index</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 3</span>
          </div>
          <div class="summary-text">AI领域的非主流观点索引。</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=42619160" target="_blank">Show HN: Startup Raising capital through Book Sales</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 2</span>
          </div>
          <div class="summary-text">初创公司通过书籍销售筹集资金。</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://github.com/jaywalnut310/vits" target="_blank">jaywalnut310/vits</a></h3>
          <div class="news-meta">
            <span class="category opensource">开源项目</span>
            <span>GitHub</span>
            <span class="importance">重要度: 9</span>
          </div>
          <div class="summary-text">VITS：带有对抗学习的条件变分自编码器，用于端到端文本到语音转换。</div>
          <div style="margin-top:5px; font-size:0.9em; color:#666;">⭐ 7587 stars</div>
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://github.com/py-why/dowhy" target="_blank">py-why/dowhy</a></h3>
          <div class="news-meta">
            <span class="category opensource">开源项目</span>
            <span>GitHub</span>
            <span class="importance">重要度: 8</span>
          </div>
          <div class="summary-text">DoWhy是一个用于因果推理的Python库，支持明确建模和测试因果假设。</div>
          <div style="margin-top:5px; font-size:0.9em; color:#666;">⭐ 7634 stars</div>
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://github.com/jessevig/bertviz" target="_blank">jessevig/bertviz</a></h3>
          <div class="news-meta">
            <span class="category opensource">开源项目</span>
            <span>GitHub</span>
            <span class="importance">重要度: 8</span>
          </div>
          <div class="summary-text">BertViz：可视化NLP模型中的注意力机制（BERT, GPT2, BART等）。</div>
          <div style="margin-top:5px; font-size:0.9em; color:#666;">⭐ 7581 stars</div>
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://github.com/vwxyzjn/cleanrl" target="_blank">vwxyzjn/cleanrl</a></h3>
          <div class="news-meta">
            <span class="category opensource">开源项目</span>
            <span>GitHub</span>
            <span class="importance">重要度: 8</span>
          </div>
          <div class="summary-text">高质量的单文件实现深度强化学习算法，具有研究友好特性（PPO, DQN, C51等）。</div>
          <div style="margin-top:5px; font-size:0.9em; color:#666;">⭐ 7577 stars</div>
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://github.com/iamtrask/Grokking-Deep-Learning" target="_blank">iamtrask/Grokking-Deep-Learning</a></h3>
          <div class="news-meta">
            <span class="category opensource">开源项目</span>
            <span>GitHub</span>
            <span class="importance">重要度: 7</span>
          </div>
          <div class="summary-text">此仓库伴随书籍“Grokking Deep Learning”。</div>
          <div style="margin-top:5px; font-size:0.9em; color:#666;">⭐ 7619 stars</div>
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://github.com/mikel-brostrom/boxmot" target="_blank">mikel-brostrom/boxmot</a></h3>
          <div class="news-meta">
            <span class="category opensource">开源项目</span>
            <span>GitHub</span>
            <span class="importance">重要度: 7</span>
          </div>
          <div class="summary-text">BoxMOT：为分割、目标检测和姿态估计模型提供可插拔的最先进多目标跟踪模块。</div>
          <div style="margin-top:5px; font-size:0.9em; color:#666;">⭐ 7579 stars</div>
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://github.com/stanfordnlp/stanza" target="_blank">stanfordnlp/stanza</a></h3>
          <div class="news-meta">
            <span class="category opensource">开源项目</span>
            <span>GitHub</span>
            <span class="importance">重要度: 7</span>
          </div>
          <div class="summary-text">斯坦福NLP Python库，用于多种人类语言的标记化、句子分割、NER和解析。</div>
          <div style="margin-top:5px; font-size:0.9em; color:#666;">⭐ 7551 stars</div>
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://github.com/llSourcell/Learn_Machine_Learning_in_3_Months" target="_blank">llSourcell/Learn_Machine_Learning_in_3_Months</a></h3>
          <div class="news-meta">
            <span class="category opensource">开源项目</span>
            <span>GitHub</span>
            <span class="importance">重要度: 6</span>
          </div>
          <div class="summary-text">这是Siraj Raval在Youtube上发布的“3个月学习机器学习”的代码。</div>
          <div style="margin-top:5px; font-size:0.9em; color:#666;">⭐ 7633 stars</div>
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://github.com/The-Pocket/PocketFlow" target="_blank">The-Pocket/PocketFlow</a></h3>
          <div class="news-meta">
            <span class="category opensource">开源项目</span>
            <span>GitHub</span>
            <span class="importance">重要度: 6</span>
          </div>
          <div class="summary-text">Pocket Flow：100行代码的LLM框架。让代理构建代理！</div>
          <div style="margin-top:5px; font-size:0.9em; color:#666;">⭐ 7561 stars</div>
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://github.com/ahmedbahaaeldin/From-0-to-Research-Scientist-resources-guide" target="_blank">ahmedbahaaeldin/From-0-to-Research-Scientist-resources-guide</a></h3>
          <div class="news-meta">
            <span class="category opensource">开源项目</span>
            <span>GitHub</span>
            <span class="importance">重要度: 5</span>
          </div>
          <div class="summary-text">为本科生或任何希望深入AI领域的人提供的详细和定制化资源指南。</div>
          <div style="margin-top:5px; font-size:0.9em; color:#666;">⭐ 7551 stars</div>
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.23773v1" target="_blank">SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 9</span>
          </div>
          <div class="summary-text">通过基于LLM的世界模型模拟推理架构构建通用目标导向代理。</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Mingkai Deng, Jinyu Hou, Yilin Shen, Hongxia Jin, Graham Neubig, Zhiting Hu, Eric Xing</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.23726v1" target="_blank">Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 9</span>
          </div>
          <div class="summary-text">LLMs have demonstrated strong mathematical reasoning abilities by leveraging
reinforcement learning with long chain-of-thought, yet they continue to
struggle with theorem proving due to the lack of clear supervision signals when
solely using natural language. Dedicated domain-specific languages like Lean
provide clear supervision via formal verification of proofs, enabling effective
training through reinforcement learning. In this work, we propose
\textbf{Seed-Prover}, a lemma-style whole-proof reasoning model. Seed-Prover
can iteratively refine its proof based on Lean feedback, proved lemmas, and
self-summarization. To solve IMO-level contest problems, we design three
test-time inference strategies that enable both deep and broad reasoning.
Seed-Prover proves $78.1\%$ of formalized past IMO problems, saturates MiniF2F,
and achieves over 50\% on PutnamBench, outperforming the previous
state-of-the-art by a large margin. To address the lack of geometry support in
Lean, we introduce a geometry reasoning engine \textbf{Seed-Geometry}, which
outperforms previous formal geometry engines. We use these two systems to
participate in IMO 2025 and fully prove 5 out of 6 problems. This work
represents a significant advancement in automated mathematical reasoning,
demonstrating the effectiveness of formal verification with long
chain-of-thought reasoning.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Luoxin Chen, Jinming Gu, Liankai Huang, Wenhao Huang, Zhicheng Jiang, Allan Jie, Xiaoran Jin, Xing Jin, Chenggang Li, Kaijing Ma, Cheng Ren, Jiawei Shen, Wenlei Shi, Tong Sun, He Sun, Jiahui Wang, Siran Wang, Zhihong Wang, Chenrui Wei, Shufa Wei, Yonghui Wu, Yuchen Wu, Yihang Xia, Huajian Xin, Fan Yang, Huaiyuan Ying, Hongyi Yuan, Zheng Yuan, Tianyang Zhan, Chi Zhang, Yue Zhang, Ge Zhang, Tianyun Zhao, Jianqiu Zhao, Yichi Zhou, Thomas Hanwen Zhu</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.23784v1" target="_blank">SUB: Benchmarking CBM Generalization via Synthetic Attribute Substitutions</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 8</span>
          </div>
          <div class="summary-text">通过合成属性替换评估概念瓶颈模型的泛化能力。</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Jessica Bader, Leander Girrbach, Stephan Alaniz, Zeynep Akata</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.23735v1" target="_blank">Distributed AI Agents for Cognitive Underwater Robot Autonomy</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 8</span>
          </div>
          <div class="summary-text">Achieving robust cognitive autonomy in robots navigating complex,
unpredictable environments remains a fundamental challenge in robotics. This
paper presents Underwater Robot Self-Organizing Autonomy (UROSA), a
groundbreaking architecture leveraging distributed Large Language Model AI
agents integrated within the Robot Operating System 2 (ROS 2) framework to
enable advanced cognitive capabilities in Autonomous Underwater Vehicles. UROSA
decentralises cognition into specialised AI agents responsible for multimodal
perception, adaptive reasoning, dynamic mission planning, and real-time
decision-making. Central innovations include flexible agents dynamically
adapting their roles, retrieval-augmented generation utilising vector databases
for efficient knowledge management, reinforcement learning-driven behavioural
optimisation, and autonomous on-the-fly ROS 2 node generation for runtime
functional extensibility. Extensive empirical validation demonstrates UROSA's
promising adaptability and reliability through realistic underwater missions in
simulation and real-world deployments, showing significant advantages over
traditional rule-based architectures in handling unforeseen scenarios,
environmental uncertainties, and novel mission objectives. This work not only
advances underwater autonomy but also establishes a scalable, safe, and
versatile cognitive robotics framework capable of generalising to a diverse
array of real-world applications.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Markus Buchholz, Ignacio Carlucho, Michele Grimaldi, Yvan R. Petillot</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.23779v1" target="_blank">Phi-Ground Tech Report: Advancing Perception in GUI Grounding</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 7</span>
          </div>
          <div class="summary-text">提升GUI接地模型在计算机使用代理中的感知能力。</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Miaosen Zhang, Ziqiang Xu, Jialiang Zhu, Qi Dai, Kai Qiu, Yifan Yang, Chong Luo, Tianyi Chen, Justin Wagle, Tim Franklin, Baining Guo</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.23751v1" target="_blank">CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 7</span>
          </div>
          <div class="summary-text">We propose CoT-Self-Instruct, a synthetic data generation method that
instructs LLMs to first reason and plan via Chain-of-Thought (CoT) based on the
given seed tasks, and then to generate a new synthetic prompt of similar
quality and complexity for use in LLM training, followed by filtering for
high-quality data with automatic metrics. In verifiable reasoning, our
synthetic data significantly outperforms existing training datasets, such as
s1k and OpenMathReasoning, across MATH500, AMC23, AIME24 and GPQA-Diamond. For
non-verifiable instruction-following tasks, our method surpasses the
performance of human or standard self-instruct prompts on both AlpacaEval 2.0
and Arena-Hard.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Ping Yu, Jack Lanchantin, Tianlu Wang, Weizhe Yuan, Olga Golovneva, Ilia Kulikov, Sainbayar Sukhbaatar, Jason Weston, Jing Xu</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.23698v1" target="_blank">Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 7</span>
          </div>
          <div class="summary-text">While Reinforcement Learning (RL) has achieved remarkable success in language
modeling, its triumph hasn't yet fully translated to visuomotor agents. A
primary challenge in RL models is their tendency to overfit specific tasks or
environments, thereby hindering the acquisition of generalizable behaviors
across diverse settings. This paper provides a preliminary answer to this
challenge by demonstrating that RL-finetuned visuomotor agents in Minecraft can
achieve zero-shot generalization to unseen worlds. Specifically, we explore
RL's potential to enhance generalizable spatial reasoning and interaction
capabilities in 3D worlds. To address challenges in multi-task RL
representation, we analyze and establish cross-view goal specification as a
unified multi-task goal space for visuomotor policies. Furthermore, to overcome
the significant bottleneck of manual task design, we propose automated task
synthesis within the highly customizable Minecraft environment for large-scale
multi-task RL training, and we construct an efficient distributed RL framework
to support this. Experimental results show RL significantly boosts interaction
success rates by $4\times$ and enables zero-shot generalization of spatial
reasoning across diverse environments, including real-world settings. Our
findings underscore the immense potential of RL training in 3D simulated
environments, especially those amenable to large-scale task generation, for
significantly advancing visuomotor agents' spatial reasoning.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Shaofei Cai, Zhancun Mu, Haiwen Xia, Bowei Zhang, Anji Liu, Yitao Liang</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.23771v1" target="_blank">Consensus-Driven Active Model Selection</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 6</span>
          </div>
          <div class="summary-text">The widespread availability of off-the-shelf machine learning models poses a
challenge: which model, of the many available candidates, should be chosen for
a given data analysis task? This question of model selection is traditionally
answered by collecting and annotating a validation dataset -- a costly and
time-intensive process. We propose a method for active model selection, using
predictions from candidate models to prioritize the labeling of test data
points that efficiently differentiate the best candidate. Our method, CODA,
performs consensus-driven active model selection by modeling relationships
between classifiers, categories, and data points within a probabilistic
framework. The framework uses the consensus and disagreement between models in
the candidate pool to guide the label acquisition process, and Bayesian
inference to update beliefs about which model is best as more information is
collected. We validate our approach by curating a collection of 26 benchmark
tasks capturing a range of model selection scenarios. CODA outperforms existing
methods for active model selection significantly, reducing the annotation
effort required to discover the best model by upwards of 70% compared to the
previous state-of-the-art. Code and data are available at
https://github.com/justinkay/coda.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Justin Kay, Grant Van Horn, Subhransu Maji, Daniel Sheldon, Sara Beery</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.23704v1" target="_blank">Enhanced Velocity Field Modeling for Gaussian Video Reconstruction</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 6</span>
          </div>
          <div class="summary-text">High-fidelity 3D video reconstruction is essential for enabling real-time
rendering of dynamic scenes with realistic motion in virtual and augmented
reality (VR/AR). The deformation field paradigm of 3D Gaussian splatting has
achieved near-photorealistic results in video reconstruction due to the great
representation capability of deep deformation networks. However, in videos with
complex motion and significant scale variations, deformation networks often
overfit to irregular Gaussian trajectories, leading to suboptimal visual
quality. Moreover, the gradient-based densification strategy designed for
static scene reconstruction proves inadequate to address the absence of dynamic
content. In light of these challenges, we propose a flow-empowered velocity
field modeling scheme tailored for Gaussian video reconstruction, dubbed
FlowGaussian-VR. It consists of two core components: a velocity field rendering
(VFR) pipeline which enables optical flow-based optimization, and a
flow-assisted adaptive densification (FAD) strategy that adjusts the number and
size of Gaussians in dynamic regions. We validate our model's effectiveness on
multi-view dynamic reconstruction and novel view synthesis with multiple
real-world datasets containing challenging motion scenarios, demonstrating not
only notable visual improvements (over 2.5 dB gain in PSNR) and less blurry
artifacts in dynamic textures, but also regularized and trackable per-Gaussian
trajectories.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Zhenyang Li, Xiaoyang Bai, Tongchen Zhang, Pengfei Shen, Weiwei Xu, Yifan Peng</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.23740v1" target="_blank">Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 5</span>
          </div>
          <div class="summary-text">Knowledge graphs (KGs) often contain sufficient information to support the
inference of new facts. Identifying logical rules not only improves the
completeness of a knowledge graph but also enables the detection of potential
errors, reveals subtle data patterns, and enhances the overall capacity for
reasoning and interpretation. However, the complexity of such rules, combined
with the unique labeling conventions of each KG, can make them difficult for
humans to understand. In this paper, we explore the potential of large language
models to generate natural language explanations for logical rules.
Specifically, we extract logical rules using the AMIE 3.5.1 rule discovery
algorithm from the benchmark dataset FB15k-237 and two large-scale datasets,
FB-CVT-REV and FB+CVT-REV. We examine various prompting strategies, including
zero- and few-shot prompting, including variable entity types, and
chain-of-thought reasoning. We conduct a comprehensive human evaluation of the
generated explanations based on correctness, clarity, and hallucination, and
also assess the use of large language models as automatic judges. Our results
demonstrate promising performance in terms of explanation correctness and
clarity, although several challenges remain for future research. All scripts
and data used in this study are publicly available at
https://github.com/idirlab/KGRule2NL}{https://github.com/idirlab/KGRule2NL.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Nasim Shirvani-Mahdavi, Devin Wingfield, Amin Ghasemi, Chengkai Li</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.23701v1" target="_blank">TextQuests: How Good are LLMs at Text-Based Video Games?</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 5</span>
          </div>
          <div class="summary-text">Evaluating AI agents within complex, interactive environments that mirror
real-world challenges is critical for understanding their practical
capabilities. While existing agent benchmarks effectively assess skills like
tool use or performance on structured tasks, they often do not fully capture an
agent's ability to operate autonomously in exploratory environments that demand
sustained, self-directed reasoning over a long and growing context. To spur the
development of agents capable of more robust intrinsic reasoning over long
horizons, we introduce TextQuests, a benchmark based on the Infocom suite of
interactive fiction games. These text-based adventures, which can take human
players over 30 hours and require hundreds of precise actions to solve, serve
as an effective proxy for evaluating AI agents on focused, stateful tasks. The
benchmark is specifically designed to assess an LLM agent's capacity for
self-contained problem-solving by precluding the use of external tools, thereby
focusing on intrinsic long-context reasoning capabilities in an exploratory
environment characterized by the need for trial-and-error learning and
sustained problem-solving within a single interactive session. We release
TextQuests at https://textquests.ai.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Long Phan, Mantas Mazeika, Andy Zou, Dan Hendrycks</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2507.23694v1" target="_blank">A survey of multi-agent geosimulation methodologies: from ABM to LLM</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 4</span>
          </div>
          <div class="summary-text">We provide a comprehensive examination of agent-based approaches that codify
the principles and linkages underlying multi-agent systems, simulations, and
information systems. Based on two decades of study, this paper confirms a
framework intended as a formal specification for geosimulation platforms. Our
findings show that large language models (LLMs) can be effectively incorporated
as agent components if they follow a structured architecture specific to
fundamental agent activities such as perception, memory, planning, and action.
This integration is precisely consistent with the architecture that we
formalize, providing a solid platform for next-generation geosimulation
systems.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Virginia Padilla, Jacinto Dávila</div>
        </div>
      
    </div>

    <div class="history-section">
        <h2>📅 历史日报目录</h2>
        <ul class="history-list">
          <li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-01.html" target="_blank">2025-08-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-31.html" target="_blank">2025-07-31</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-30.html" target="_blank">2025-07-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-29.html" target="_blank">2025-07-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-27.html" target="_blank">2025-07-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-26.html" target="_blank">2025-07-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-25.html" target="_blank">2025-07-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-24.html" target="_blank">2025-07-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-23.html" target="_blank">2025-07-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-22.html" target="_blank">2025-07-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-21.html" target="_blank">2025-07-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-20.html" target="_blank">2025-07-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-19.html" target="_blank">2025-07-19</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-18.html" target="_blank">2025-07-18</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-17.html" target="_blank">2025-07-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-16.html" target="_blank">2025-07-16</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-15.html" target="_blank">2025-07-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-13.html" target="_blank">2025-07-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-12.html" target="_blank">2025-07-12</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-11.html" target="_blank">2025-07-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-10.html" target="_blank">2025-07-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-09.html" target="_blank">2025-07-09</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-08.html" target="_blank">2025-07-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-07.html" target="_blank">2025-07-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-06.html" target="_blank">2025-07-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-05.html" target="_blank">2025-07-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-04.html" target="_blank">2025-07-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-03.html" target="_blank">2025-07-03</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-02.html" target="_blank">2025-07-02</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-01.html" target="_blank">2025-07-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-30.html" target="_blank">2025-06-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-29.html" target="_blank">2025-06-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-28.html" target="_blank">2025-06-28</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-27.html" target="_blank">2025-06-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-26.html" target="_blank">2025-06-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-25.html" target="_blank">2025-06-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-24.html" target="_blank">2025-06-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-23.html" target="_blank">2025-06-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-22.html" target="_blank">2025-06-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-21.html" target="_blank">2025-06-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-20.html" target="_blank">2025-06-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-19.html" target="_blank">2025-06-19</a></li>
        </ul>
      </div>

    <div class="footer">
      🔄 由 Cloudflare Workers + DeepSeek 自动生成 | 更新时间: 2025/8/2 22:03:40
    </div>
  </div>
</body>
</html>