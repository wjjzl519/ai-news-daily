<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AIèµ„è®¯æ—¥æŠ¥ - 2026/1/27</title>
  <style>
    /* æ·»åŠ æŒ‰é’®æ ·å¼ */
    .nav-buttons {
      display: flex;
      gap: 15px;
      justify-content: center;
      margin-top: 15px;
      flex-wrap: wrap;
    }
    .nav-button {
      background: rgba(255, 255, 255, 0.2);
      border: 1px solid rgba(255, 255, 255, 0.4);
      border-radius: 20px;
      padding: 6px 15px;
      color: white;
      text-decoration: none;
      display: inline-flex;
      align-items: center;
      transition: all 0.3s;
      font-size: 0.9em;
    }
    .nav-button:hover {
      background: rgba(255, 255, 255, 0.3);
      transform: translateY(-2px);
    }
    /* å…¶ä»–æ ·å¼ä¿æŒä¸å˜ */
    body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background: #f5f5f5; color: #333; margin: 0; padding: 0; }
    .container { max-width: 1200px; margin: auto; padding: 20px; }
    .header { background: linear-gradient(135deg, #667eea, #764ba2); color: #fff; padding: 40px 20px; border-radius: 10px; text-align: center; }
    .header h1 { font-size: 2.5em; margin: 0; }
    .summary, .history-section { background: #fff; margin-top: 30px; padding: 25px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
    .summary h2, .history-section h2 { color: #667eea; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 15px; }
    .news-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(350px, 1fr)); gap: 20px; margin-top: 30px; }
    .news-item { background: white; border-radius: 10px; padding: 20px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
    .news-item h3 a { text-decoration: none; color: #333; font-size: 1.1em; }
    .news-item h3 a:hover { color: #667eea; }
    .news-meta { font-size: 0.9em; color: #666; margin-bottom: 10px; }
    .category { display: inline-block; padding: 4px 10px; border-radius: 20px; font-size: 0.8em; margin-right: 8px; }
    .category.industry { background: #e3f2fd; color: #1976d2; }
    .category.academic { background: #f3e5f5; color: #7b1fa2; }
    .category.opensource { background: #e8f5e9; color: #388e3c; }
    .summary-text { margin-top: 10px; color: #555; }
    .importance { background: #ff9800; color: white; padding: 2px 8px; border-radius: 10px; font-size: 0.75em; margin-left: 10px; }
    .history-list { list-style: none; padding-left: 0; }
    .history-list li { margin: 5px 0; }
    .history-list a { text-decoration: none; color: #333; }
    .history-list a:hover { color: #667eea; }
    .footer { text-align: center; font-size: 0.9em; color: #999; padding: 20px; margin-top: 40px; }
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>ğŸ¤– AIèµ„è®¯æ—¥æŠ¥</h1>
      <p>2026/1/27 | äººå·¥æ™ºèƒ½é¢†åŸŸæœ€æ–°åŠ¨æ€</p>
      <div class="nav-buttons">
        <a href="../daily/2026-01-26.html" class="nav-button">
          ğŸ”™ æŸ¥çœ‹æ˜¨æ—¥å†…å®¹
        </a>
        <a href="../" class="nav-button">
          ğŸ  è¿”å›ä¸»é¡µ
        </a>
      </div>
    </div>

    <div class="summary">
      <h2>ğŸ“Š ä»Šæ—¥è¶‹åŠ¿æ€»ç»“</h2>
      <p>AIé¢†åŸŸèµ„è®¯æ•´ä½“å‘ˆç°å¤šå…ƒåŒ–è¶‹åŠ¿ï¼Œæ¶µç›–æŠ€æœ¯ã€äº§ä¸šã€ä¼¦ç†ä¸äººæ‰ç­‰å¤šä¸ªç»´åº¦ã€‚æŠ€æœ¯å±‚é¢å…³æ³¨AIç®—æ³•å®é™…åº”ç”¨ç—›ç‚¹ä¸è¿›å±•é€Ÿåº¦çš„è®¨è®ºï¼›äº§ä¸šæ–¹é¢æ¶‰åŠå¼€æºè®¸å¯ã€å•†ä¸šæ¨¡å¼ä¸æ³•è§„å½±å“ï¼›ä¼¦ç†ä¸è®¤çŸ¥é¢†åŸŸåŒ…æ‹¬å¯¹AIç‚’ä½œç°è±¡çš„æ‰¹åˆ¤ä¸å­¦ä¹ è·¯å¾„æ¢è®¨ï¼›äººæ‰éœ€æ±‚ä½“ç°åœ¨ç”Ÿç‰©ä¿¡æ¯å­¦ç­‰äº¤å‰å­¦ç§‘å²—ä½ã€‚æ•´ä½“æ˜¾ç¤ºAIæ­£ä»æŠ€æœ¯æ¢ç´¢å‘å®é™…åº”ç”¨ä¸è§„èŒƒå‘å±•è¿‡æ¸¡ï¼ŒåŒæ—¶ä¿æŒå¯¹åŸºç¡€æŠ€æœ¯ä¸é•¿æœŸä»·å€¼çš„å…³æ³¨ã€‚</p>
    </div>

    <div class="news-grid">
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=44848018" target="_blank">Why Boring Businesses Outlast AI Hype Cycles</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 9</span>
          </div>
          <div class="summary-text">æ¢è®¨åŠ¡å®ä¼ä¸šå¦‚ä½•è¶…è¶ŠAIç‚’ä½œå‘¨æœŸï¼Œå¼ºè°ƒé•¿æœŸä»·å€¼ä¸å¯æŒç»­æ€§ã€‚</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=27111719" target="_blank">Ask HN: What's the pain using current AI algorithms?</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 8</span>
          </div>
          <div class="summary-text">è®¨è®ºå½“å‰AIç®—æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„ç—›ç‚¹ä¸æŒ‘æˆ˜ã€‚</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=36233487" target="_blank">Ask HN: Is the rate of progress in AI exponential?</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 8</span>
          </div>
          <div class="summary-text">æ¢è®¨AIæŠ€æœ¯å‘å±•é€Ÿåº¦æ˜¯å¦å‘ˆæŒ‡æ•°çº§å¢é•¿åŠå…¶å½±å“ã€‚</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://lekta.ai/blog/natural-language-processing-artificial-intelligence-machine-learning-bots-a-passing-trend-or-much-more" target="_blank">NLP, AI, ML, bots â€“ a passing trend or much more? What's your take on this?</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 7</span>
          </div>
          <div class="summary-text">è®¨è®ºNLPã€AIã€MLç­‰æŠ€æœ¯æ˜¯çŸ­æš‚è¶‹åŠ¿è¿˜æ˜¯å…·æœ‰æ·±è¿œå½±å“ã€‚</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=36431356" target="_blank">Ask HN: Anyone concerned about NYC Local Law 144?</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 7</span>
          </div>
          <div class="summary-text">Ask HN: Anyone concerned about NYC Local Law 144?</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=46562867" target="_blank">MIT Non-AI License</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 6</span>
          </div>
          <div class="summary-text">ä»‹ç»MITéAIè®¸å¯è¯ï¼Œæ¶‰åŠå¼€æºè½¯ä»¶åœ¨AIé¢†åŸŸçš„è®¸å¯é—®é¢˜ã€‚</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=35103021" target="_blank">The AI Crackpot Index</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 6</span>
          </div>
          <div class="summary-text">æå‡ºAIé¢†åŸŸç‚’ä½œä¸ä¸å®è¨€è®ºçš„è¯„ä¼°æŒ‡æ•°ï¼Œæ‰¹åˆ¤æ€§åˆ†æè¡Œä¸šç°è±¡ã€‚</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=44899994" target="_blank">Ask HN: What would you read to learn about "artificial intelligence"?</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">æ¢è®¨å­¦ä¹ äººå·¥æ™ºèƒ½çš„æ¨èé˜…è¯»ææ–™ä¸å­¦ä¹ è·¯å¾„ã€‚</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=15140715" target="_blank">Bioinformatician</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">ç”Ÿç‰©ä¿¡æ¯å­¦å²—ä½æ‹›è˜ä¿¡æ¯ï¼Œä½“ç°AIåœ¨ç”Ÿå‘½ç§‘å­¦é¢†åŸŸçš„åº”ç”¨éœ€æ±‚ã€‚</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=401541" target="_blank">Common Lisp + Machine Learning Internship at Google (Mountain View, CA)</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 4</span>
          </div>
          <div class="summary-text">è°·æ­Œæ‹›è˜Common Lispä¸æœºå™¨å­¦ä¹ å®ä¹ ç”Ÿï¼Œåæ˜ æŠ€æœ¯æ ˆå¤šæ ·æ€§ã€‚</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=42619160" target="_blank">Show HN: Startup Raising capital through Book Sales</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 3</span>
          </div>
          <div class="summary-text">åˆåˆ›å…¬å¸é€šè¿‡ä¹¦ç±é”€å”®ç­¹é›†èµ„é‡‘ï¼Œå±•ç¤ºéä¼ ç»Ÿèèµ„æ¨¡å¼ã€‚</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://www.yourobot.io/blog/uncategorized/the-next-bill-gates-or-albert-einstein-in-ai-artificial-intelligence-will-produce-the-god-algorithm-of-machine-learning-where-a-machine-will-be-able-to-do-and-learn-anything-by-its-self/" target="_blank">The Next Bill Gates or Albert Einstein in AI â€œChris Clarkâ€ â€“ Yourobot</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 2</span>
          </div>
          <div class="summary-text">é¢„æµ‹AIé¢†åŸŸå¯èƒ½å‡ºç°åƒæ¯”å°”Â·ç›–èŒ¨æˆ–çˆ±å› æ–¯å¦çš„çªç ´æ€§äººç‰©ã€‚</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2601.18796v1" target="_blank">ctELM: Decoding and Manipulating Embeddings of Clinical Trials with Embedding Language Models</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Text embeddings have become an essential part of a variety of language applications. However, methods for interpreting, exploring and reversing embedding spaces are limited, reducing transparency and precluding potentially valuable generative use cases. In this work, we align Large Language Models to embeddings of clinical trials using the recently reported Embedding Language Model (ELM) method. We develop an open-source, domain-agnostic ELM architecture and training framework, design training tasks for clinical trials, and introduce an expert-validated synthetic dataset. We then train a series of ELMs exploring the impact of tasks and training regimes. Our final model, ctELM, can accurately describe and compare unseen clinical trials from embeddings alone and produce plausible clinical trials from novel vectors. We further show that generated trial abstracts are responsive to moving embeddings along concept vectors for age and sex of study subjects. Our public ELM implementation and experimental results will aid the alignment of Large Language Models to embedding spaces in the biomedical domain and beyond.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2601.18795v1" target="_blank">Reuse your FLOPs: Scaling RL on Hard Problems by Conditioning on Very Off-Policy Prefixes</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Typical reinforcement learning (RL) methods for LLM reasoning waste compute on hard problems, where correct on-policy traces are rare, policy gradients vanish, and learning stalls. To bootstrap more efficient RL, we consider reusing old sampling FLOPs (from prior inference or RL training) in the form of off-policy traces. Standard off-policy methods supervise against off-policy data, causing instabilities during RL optimization. We introduce PrefixRL, where we condition on the prefix of successful off-policy traces and run on-policy RL to complete them, side-stepping off-policy instabilities. PrefixRL boosts the learning signal on hard problems by modulating the difficulty of the problem through the off-policy prefix length. We prove that the PrefixRL objective is not only consistent with the standard RL objective but also more sample efficient. Empirically, we discover back-generalization: training only on prefixed problems generalizes to out-of-distribution unprefixed performance, with learned strategies often differing from those in the prefix. In our experiments, we source the off-policy traces by rejection sampling with the base model, creating a self-improvement loop. On hard reasoning problems, PrefixRL reaches the same training reward 2x faster than the strongest baseline (SFT on off-policy data then RL), even after accounting for the compute spent on the initial rejection sampling, and increases the final reward by 3x. The gains transfer to held-out benchmarks, and PrefixRL is still effective when off-policy traces are derived from a different model family, validating its flexibility in practical settings.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2601.18791v1" target="_blank">Subword-Based Comparative Linguistics across 242 Languages Using Wikipedia Glottosets</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">We present a large-scale comparative study of 242 Latin and Cyrillic-script languages using subword-based methodologies. By constructing 'glottosets' from Wikipedia lexicons, we introduce a framework for simultaneous cross-linguistic comparison via Byte-Pair Encoding (BPE). Our approach utilizes rank-based subword vectors to analyze vocabulary overlap, lexical divergence, and language similarity at scale. Evaluations demonstrate that BPE segmentation aligns with morpheme boundaries 95% better than random baseline across 15 languages (F1 = 0.34 vs 0.15). BPE vocabulary similarity correlates significantly with genetic language relatedness (Mantel r = 0.329, p &lt; 0.001), with Romance languages forming the tightest cluster (mean distance 0.51) and cross-family pairs showing clear separation (0.82). Analysis of 26,939 cross-linguistic homographs reveals that 48.7% receive different segmentations across related languages, with variation correlating to phylogenetic distance. Our results provide quantitative macro-linguistic insights into lexical patterns across typologically diverse languages within a unified analytical framework.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2601.18785v1" target="_blank">Design Techniques for LLM-Powered Interactive Storytelling: A Case Study of the Dramamancer System</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">The rise of Large Language Models (LLMs) has enabled a new paradigm for bridging authorial intent and player agency in interactive narrative. We consider this paradigm through the example of Dramamancer, a system that uses an LLM to transform author-created story schemas into player-driven playthroughs. This extended abstract outlines some design techniques and evaluation considerations associated with this system.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2601.18783v1" target="_blank">Multi-Objective Reinforcement Learning for Efficient Tactical Decision Making for Trucks in Highway Traffic</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Balancing safety, efficiency, and operational costs in highway driving poses a challenging decision-making problem for heavy-duty vehicles. A central difficulty is that conventional scalar reward formulations, obtained by aggregating these competing objectives, often obscure the structure of their trade-offs. We present a Proximal Policy Optimization based multi-objective reinforcement learning framework that learns a continuous set of policies explicitly representing these trade-offs and evaluates it on a scalable simulation platform for tactical decision making in trucks. The proposed approach learns a continuous set of Pareto-optimal policies that capture the trade-offs among three conflicting objectives: safety, quantified in terms of collisions and successful completion; energy efficiency and time efficiency, quantified using energy cost and driver cost, respectively. The resulting Pareto frontier is smooth and interpretable, enabling flexibility in choosing driving behavior along different conflicting objectives. This framework allows seamless transitions between different driving policies without retraining, yielding a robust and adaptive decision-making strategy for autonomous trucking applications.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2601.18779v1" target="_blank">POPE: Learning to Reason on Hard Problems via Privileged On-Policy Exploration</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Reinforcement learning (RL) has improved the reasoning abilities of large language models (LLMs), yet state-of-the-art methods still fail to learn on many training problems. On hard problems, on-policy RL rarely explores even a single correct rollout, yielding zero reward and no learning signal for driving improvement. We find that natural solutions to remedy this exploration problem from classical RL, such as entropy bonuses, more permissive clipping of the importance ratio, or direct optimization of pass@k objectives, do not resolve this issue and often destabilize optimization without improving solvability. A natural alternative is to leverage transfer from easier problems. However, we show that mixing easy and hard problems during RL training is counterproductive due to ray interference, where optimization focuses on already-solvable problems in a way that actively inhibits progress on harder ones. To address this challenge, we introduce Privileged On-Policy Exploration (POPE), an approach that leverages human- or other oracle solutions as privileged information to guide exploration on hard problems, unlike methods that use oracle solutions as training targets (e.g., off-policy RL methods or warmstarting from SFT). POPE augments hard problems with prefixes of oracle solutions, enabling RL to obtain non-zero rewards during guided rollouts. Crucially, the resulting behaviors transfer back to the original, unguided problems through a synergy between instruction-following and reasoning. Empirically, POPE expands the set of solvable problems and substantially improves performance on challenging reasoning benchmarks.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2601.18777v1" target="_blank">PRECISE: Reducing the Bias of LLM Evaluations Using Prediction-Powered Ranking Estimation</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Evaluating the quality of search, ranking and RAG systems traditionally requires a significant number of human relevance annotations. In recent times, several deployed systems have explored the usage of Large Language Models (LLMs) as automated judges for this task while their inherent biases prevent direct use for metric estimation. We present a statistical framework extending Prediction-Powered Inference (PPI) that combines minimal human annotations with LLM judgments to produce reliable estimates of metrics which require sub-instance annotations. Our method requires as few as 100 human-annotated queries and 10,000 unlabeled examples, reducing annotation requirements significantly compared to traditional approaches. We formulate our proposed framework (PRECISE) for inference of relevance uplift for an LLM-based query reformulation application, extending PPI to sub-instance annotations at the query-document level. By reformulating the metric-integration space, we reduced the computational complexity from O(2^|C|) to O(2^K), where |C| represents corpus size (in order of millions). Detailed experiments across prominent retrieval datasets demonstrate that our method reduces the variance of estimates for the business-critical Precision@K metric, while effectively correcting for LLM bias in low-resource settings.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2601.18771v1" target="_blank">Dep-Search: Learning Dependency-Aware Reasoning Traces with Persistent Memory</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Large Language Models (LLMs) have demonstrated remarkable capabilities in complex reasoning tasks, particularly when augmented with search mechanisms that enable systematic exploration of external knowledge bases. The field has evolved from traditional retrieval-augmented generation (RAG) frameworks to more sophisticated search-based frameworks that orchestrate multi-step reasoning through explicit search strategies. However, existing search frameworks still rely heavily on implicit natural language reasoning to determine search strategies and how to leverage retrieved information across reasoning steps. This reliance on implicit reasoning creates fundamental challenges for managing dependencies between sub-questions, efficiently reusing previously retrieved knowledge, and learning optimal search strategies through reinforcement learning. To address these limitations, we propose Dep-Search, a dependency-aware search framework that advances beyond existing search frameworks by integrating structured reasoning, retrieval, and persistent memory through GRPO. Dep-Search introduces explicit control mechanisms that enable the model to decompose questions with dependency relationships, retrieve information when needed, access previously stored knowledge from memory, and summarize long reasoning contexts into reusable memory entries. Through extensive experiments on seven diverse question answering datasets, we demonstrate that Dep-Search significantly enhances LLMs' ability to tackle complex multi-hop reasoning tasks, achieving substantial improvements over strong baselines across different model scales.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2601.18754v1" target="_blank">$Î±^3$-SecBench: A Large-Scale Evaluation Suite of Security, Resilience, and Trust for LLM-based UAV Agents over 6G Networks</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Autonomous unmanned aerial vehicle (UAV) systems are increasingly deployed in safety-critical, networked environments where they must operate reliably in the presence of malicious adversaries. While recent benchmarks have evaluated large language model (LLM)-based UAV agents in reasoning, navigation, and efficiency, systematic assessment of security, resilience, and trust under adversarial conditions remains largely unexplored, particularly in emerging 6G-enabled settings. We introduce $Î±^{3}$-SecBench, the first large-scale evaluation suite for assessing the security-aware autonomy of LLM-based UAV agents under realistic adversarial interference. Building on multi-turn conversational UAV missions from $Î±^{3}$-Bench, the framework augments benign episodes with 20,000 validated security overlay attack scenarios targeting seven autonomy layers, including sensing, perception, planning, control, communication, edge/cloud infrastructure, and LLM reasoning. $Î±^{3}$-SecBench evaluates agents across three orthogonal dimensions: security (attack detection and vulnerability attribution), resilience (safe degradation behavior), and trust (policy-compliant tool usage). We evaluate 23 state-of-the-art LLMs from major industrial providers and leading AI labs using thousands of adversarially augmented UAV episodes sampled from a corpus of 113,475 missions spanning 175 threat types. While many models reliably detect anomalous behavior, effective mitigation, vulnerability attribution, and trustworthy control actions remain inconsistent. Normalized overall scores range from 12.9% to 57.1%, highlighting a significant gap between anomaly detection and security-aware autonomous decision-making. We release $Î±^{3}$-SecBench on GitHub: https://github.com/maferrag/AlphaSecBench</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2601.18753v1" target="_blank">HalluGuard: Demystifying Data-Driven and Reasoning-Driven Hallucinations in LLMs</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">The reliability of Large Language Models (LLMs) in high-stakes domains such as healthcare, law, and scientific discovery is often compromised by hallucinations. These failures typically stem from two sources: data-driven hallucinations and reasoning-driven hallucinations. However, existing detection methods usually address only one source and rely on task-specific heuristics, limiting their generalization to complex scenarios. To overcome these limitations, we introduce the Hallucination Risk Bound, a unified theoretical framework that formally decomposes hallucination risk into data-driven and reasoning-driven components, linked respectively to training-time mismatches and inference-time instabilities. This provides a principled foundation for analyzing how hallucinations emerge and evolve. Building on this foundation, we introduce HalluGuard, an NTK-based score that leverages the induced geometry and captured representations of the NTK to jointly identify data-driven and reasoning-driven hallucinations. We evaluate HalluGuard on 10 diverse benchmarks, 11 competitive baselines, and 9 popular LLM backbones, consistently achieving state-of-the-art performance in detecting diverse forms of LLM hallucinations.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2601.18751v1" target="_blank">Trust, Don't Trust, or Flip: Robust Preference-Based Reinforcement Learning with Multi-Expert Feedback</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Preference-based reinforcement learning (PBRL) offers a promising alternative to explicit reward engineering by learning from pairwise trajectory comparisons. However, real-world preference data often comes from heterogeneous annotators with varying reliability; some accurate, some noisy, and some systematically adversarial. Existing PBRL methods either treat all feedback equally or attempt to filter out unreliable sources, but both approaches fail when faced with adversarial annotators who systematically provide incorrect preferences. We introduce TriTrust-PBRL (TTP), a unified framework that jointly learns a shared reward model and expert-specific trust parameters from multi-expert preference feedback. The key insight is that trust parameters naturally evolve during gradient-based optimization to be positive (trust), near zero (ignore), or negative (flip), enabling the model to automatically invert adversarial preferences and recover useful signal rather than merely discarding corrupted feedback. We provide theoretical analysis establishing identifiability guarantees and detailed gradient analysis that explains how expert separation emerges naturally during training without explicit supervision. Empirically, we evaluate TTP on four diverse domains spanning manipulation tasks (MetaWorld) and locomotion (DM Control) under various corruption scenarios. TTP achieves state-of-the-art robustness, maintaining near-oracle performance under adversarial corruption while standard PBRL methods fail catastrophically. Notably, TTP outperforms existing baselines by successfully learning from mixed expert pools containing both reliable and adversarial annotators, all while requiring no expert features beyond identification indices and integrating seamlessly with existing PBRL pipelines.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2601.18747v1" target="_blank">Capturing P: On the Expressive Power and Efficient Evaluation of Boolean Retrieval</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Modern information retrieval is transitioning from simple document filtering to complex, neuro-symbolic reasoning workflows. However, current retrieval architectures face a fundamental efficiency dilemma when handling the rigorous logical and arithmetic constraints required by this new paradigm. Standard iterator-based engines (Document-at-a-Time) do not natively support complex, nested logic graphs; forcing them to execute such queries typically results in intractable runtime performance. Conversely, naive recursive approaches (Term-at-a-Time), while capable of supporting these structures, suffer from prohibitive memory consumption when enforcing broad logical exclusions. In this paper, we propose that a retrieval engine must be capable of ``Capturing $\mathbf{P}$'' -- evaluating any polynomial-time property directly over its index in a computationally efficient manner. We define a formal Retrieval Language ($\mathcal{L}_R$) based on Directed Acyclic Graphs (DAGs) and prove it precisely captures the complexity class $\mathbf{P}$. We introduce \texttt{ComputePN}, a novel evaluation algorithm that makes $\mathcal{L}_R$ tractable. By combining native DAG traversal with a memory-efficient ``Positive-Negative'' response mechanism, \texttt{ComputePN} ensures the efficient evaluation of any query in $\mathcal{L}_R$. This work establishes the theoretical foundation for turning the search index into a general-purpose computational engine.</div>
          
          
        </div>
      
    </div>

    <div class="history-section">
        <h2>ğŸ“… å†å²æ—¥æŠ¥ç›®å½•</h2>
        <ul class="history-list">
          <li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-26.html" target="_blank">2026-01-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-25.html" target="_blank">2026-01-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-24.html" target="_blank">2026-01-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-23.html" target="_blank">2026-01-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-22.html" target="_blank">2026-01-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-21.html" target="_blank">2026-01-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-20.html" target="_blank">2026-01-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-19.html" target="_blank">2026-01-19</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-18.html" target="_blank">2026-01-18</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-17.html" target="_blank">2026-01-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-16.html" target="_blank">2026-01-16</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-15.html" target="_blank">2026-01-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-14.html" target="_blank">2026-01-14</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-13.html" target="_blank">2026-01-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-12.html" target="_blank">2026-01-12</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-11.html" target="_blank">2026-01-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-10.html" target="_blank">2026-01-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-09.html" target="_blank">2026-01-09</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-08.html" target="_blank">2026-01-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-07.html" target="_blank">2026-01-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-06.html" target="_blank">2026-01-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-05.html" target="_blank">2026-01-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-04.html" target="_blank">2026-01-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-03.html" target="_blank">2026-01-03</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-02.html" target="_blank">2026-01-02</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2026-01-01.html" target="_blank">2026-01-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-31.html" target="_blank">2025-12-31</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-30.html" target="_blank">2025-12-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-29.html" target="_blank">2025-12-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-28.html" target="_blank">2025-12-28</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-27.html" target="_blank">2025-12-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-26.html" target="_blank">2025-12-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-25.html" target="_blank">2025-12-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-24.html" target="_blank">2025-12-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-23.html" target="_blank">2025-12-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-22.html" target="_blank">2025-12-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-21.html" target="_blank">2025-12-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-20.html" target="_blank">2025-12-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-19.html" target="_blank">2025-12-19</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-18.html" target="_blank">2025-12-18</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-17.html" target="_blank">2025-12-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-16.html" target="_blank">2025-12-16</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-15.html" target="_blank">2025-12-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-14.html" target="_blank">2025-12-14</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-13.html" target="_blank">2025-12-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-12.html" target="_blank">2025-12-12</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-11.html" target="_blank">2025-12-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-10.html" target="_blank">2025-12-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-09.html" target="_blank">2025-12-09</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-08.html" target="_blank">2025-12-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-07.html" target="_blank">2025-12-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-06.html" target="_blank">2025-12-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-05.html" target="_blank">2025-12-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-04.html" target="_blank">2025-12-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-03.html" target="_blank">2025-12-03</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-02.html" target="_blank">2025-12-02</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-01.html" target="_blank">2025-12-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-30.html" target="_blank">2025-11-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-29.html" target="_blank">2025-11-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-28.html" target="_blank">2025-11-28</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-27.html" target="_blank">2025-11-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-26.html" target="_blank">2025-11-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-25.html" target="_blank">2025-11-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-24.html" target="_blank">2025-11-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-23.html" target="_blank">2025-11-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-22.html" target="_blank">2025-11-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-21.html" target="_blank">2025-11-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-20.html" target="_blank">2025-11-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-19.html" target="_blank">2025-11-19</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-18.html" target="_blank">2025-11-18</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-17.html" target="_blank">2025-11-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-16.html" target="_blank">2025-11-16</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-15.html" target="_blank">2025-11-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-14.html" target="_blank">2025-11-14</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-13.html" target="_blank">2025-11-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-12.html" target="_blank">2025-11-12</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-11.html" target="_blank">2025-11-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-10.html" target="_blank">2025-11-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-09.html" target="_blank">2025-11-09</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-08.html" target="_blank">2025-11-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-07.html" target="_blank">2025-11-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-06.html" target="_blank">2025-11-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-05.html" target="_blank">2025-11-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-04.html" target="_blank">2025-11-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-03.html" target="_blank">2025-11-03</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-02.html" target="_blank">2025-11-02</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-01.html" target="_blank">2025-11-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-31.html" target="_blank">2025-10-31</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-30.html" target="_blank">2025-10-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-29.html" target="_blank">2025-10-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-28.html" target="_blank">2025-10-28</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-27.html" target="_blank">2025-10-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-26.html" target="_blank">2025-10-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-25.html" target="_blank">2025-10-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-24.html" target="_blank">2025-10-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-23.html" target="_blank">2025-10-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-22.html" target="_blank">2025-10-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-21.html" target="_blank">2025-10-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-20.html" target="_blank">2025-10-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-19.html" target="_blank">2025-10-19</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-18.html" target="_blank">2025-10-18</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-17.html" target="_blank">2025-10-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-16.html" target="_blank">2025-10-16</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-15.html" target="_blank">2025-10-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-14.html" target="_blank">2025-10-14</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-13.html" target="_blank">2025-10-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-12.html" target="_blank">2025-10-12</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-11.html" target="_blank">2025-10-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-10.html" target="_blank">2025-10-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-09.html" target="_blank">2025-10-09</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-08.html" target="_blank">2025-10-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-07.html" target="_blank">2025-10-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-06.html" target="_blank">2025-10-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-05.html" target="_blank">2025-10-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-04.html" target="_blank">2025-10-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-03.html" target="_blank">2025-10-03</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-02.html" target="_blank">2025-10-02</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-01.html" target="_blank">2025-10-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-30.html" target="_blank">2025-09-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-29.html" target="_blank">2025-09-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-28.html" target="_blank">2025-09-28</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-27.html" target="_blank">2025-09-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-26.html" target="_blank">2025-09-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-25.html" target="_blank">2025-09-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-24.html" target="_blank">2025-09-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-23.html" target="_blank">2025-09-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-22.html" target="_blank">2025-09-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-21.html" target="_blank">2025-09-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-20.html" target="_blank">2025-09-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-19.html" target="_blank">2025-09-19</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-18.html" target="_blank">2025-09-18</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-17.html" target="_blank">2025-09-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-16.html" target="_blank">2025-09-16</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-15.html" target="_blank">2025-09-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-14.html" target="_blank">2025-09-14</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-13.html" target="_blank">2025-09-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-12.html" target="_blank">2025-09-12</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-11.html" target="_blank">2025-09-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-10.html" target="_blank">2025-09-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-09.html" target="_blank">2025-09-09</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-08.html" target="_blank">2025-09-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-07.html" target="_blank">2025-09-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-06.html" target="_blank">2025-09-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-05.html" target="_blank">2025-09-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-04.html" target="_blank">2025-09-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-30.html" target="_blank">2025-08-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-25.html" target="_blank">2025-08-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-24.html" target="_blank">2025-08-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-23.html" target="_blank">2025-08-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-22.html" target="_blank">2025-08-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-21.html" target="_blank">2025-08-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-20.html" target="_blank">2025-08-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-17.html" target="_blank">2025-08-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-15.html" target="_blank">2025-08-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-14.html" target="_blank">2025-08-14</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-13.html" target="_blank">2025-08-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-11.html" target="_blank">2025-08-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-10.html" target="_blank">2025-08-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-08.html" target="_blank">2025-08-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-07.html" target="_blank">2025-08-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-06.html" target="_blank">2025-08-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-05.html" target="_blank">2025-08-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-04.html" target="_blank">2025-08-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-03.html" target="_blank">2025-08-03</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-02.html" target="_blank">2025-08-02</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-01.html" target="_blank">2025-08-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-31.html" target="_blank">2025-07-31</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-30.html" target="_blank">2025-07-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-29.html" target="_blank">2025-07-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-27.html" target="_blank">2025-07-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-26.html" target="_blank">2025-07-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-25.html" target="_blank">2025-07-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-24.html" target="_blank">2025-07-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-23.html" target="_blank">2025-07-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-22.html" target="_blank">2025-07-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-21.html" target="_blank">2025-07-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-20.html" target="_blank">2025-07-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-19.html" target="_blank">2025-07-19</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-18.html" target="_blank">2025-07-18</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-17.html" target="_blank">2025-07-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-16.html" target="_blank">2025-07-16</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-15.html" target="_blank">2025-07-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-13.html" target="_blank">2025-07-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-12.html" target="_blank">2025-07-12</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-11.html" target="_blank">2025-07-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-10.html" target="_blank">2025-07-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-09.html" target="_blank">2025-07-09</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-08.html" target="_blank">2025-07-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-07.html" target="_blank">2025-07-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-06.html" target="_blank">2025-07-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-05.html" target="_blank">2025-07-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-04.html" target="_blank">2025-07-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-03.html" target="_blank">2025-07-03</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-02.html" target="_blank">2025-07-02</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-01.html" target="_blank">2025-07-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-30.html" target="_blank">2025-06-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-29.html" target="_blank">2025-06-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-28.html" target="_blank">2025-06-28</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-27.html" target="_blank">2025-06-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-26.html" target="_blank">2025-06-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-25.html" target="_blank">2025-06-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-24.html" target="_blank">2025-06-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-23.html" target="_blank">2025-06-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-22.html" target="_blank">2025-06-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-21.html" target="_blank">2025-06-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-20.html" target="_blank">2025-06-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-19.html" target="_blank">2025-06-19</a></li>
        </ul>
      </div>

    <div class="footer">
      ğŸ”„ ç”± Cloudflare Workers + DeepSeek è‡ªåŠ¨ç”Ÿæˆ | æ›´æ–°æ—¶é—´: 2026/1/27 22:01:23
    </div>
  </div>
</body>
</html>