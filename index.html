<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AIèµ„è®¯æ—¥æŠ¥ - 2025/12/3</title>
  <style>
    /* æ·»åŠ æŒ‰é’®æ ·å¼ */
    .nav-buttons {
      display: flex;
      gap: 15px;
      justify-content: center;
      margin-top: 15px;
      flex-wrap: wrap;
    }
    .nav-button {
      background: rgba(255, 255, 255, 0.2);
      border: 1px solid rgba(255, 255, 255, 0.4);
      border-radius: 20px;
      padding: 6px 15px;
      color: white;
      text-decoration: none;
      display: inline-flex;
      align-items: center;
      transition: all 0.3s;
      font-size: 0.9em;
    }
    .nav-button:hover {
      background: rgba(255, 255, 255, 0.3);
      transform: translateY(-2px);
    }
    /* å…¶ä»–æ ·å¼ä¿æŒä¸å˜ */
    body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background: #f5f5f5; color: #333; margin: 0; padding: 0; }
    .container { max-width: 1200px; margin: auto; padding: 20px; }
    .header { background: linear-gradient(135deg, #667eea, #764ba2); color: #fff; padding: 40px 20px; border-radius: 10px; text-align: center; }
    .header h1 { font-size: 2.5em; margin: 0; }
    .summary, .history-section { background: #fff; margin-top: 30px; padding: 25px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
    .summary h2, .history-section h2 { color: #667eea; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 15px; }
    .news-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(350px, 1fr)); gap: 20px; margin-top: 30px; }
    .news-item { background: white; border-radius: 10px; padding: 20px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
    .news-item h3 a { text-decoration: none; color: #333; font-size: 1.1em; }
    .news-item h3 a:hover { color: #667eea; }
    .news-meta { font-size: 0.9em; color: #666; margin-bottom: 10px; }
    .category { display: inline-block; padding: 4px 10px; border-radius: 20px; font-size: 0.8em; margin-right: 8px; }
    .category.industry { background: #e3f2fd; color: #1976d2; }
    .category.academic { background: #f3e5f5; color: #7b1fa2; }
    .category.opensource { background: #e8f5e9; color: #388e3c; }
    .summary-text { margin-top: 10px; color: #555; }
    .importance { background: #ff9800; color: white; padding: 2px 8px; border-radius: 10px; font-size: 0.75em; margin-left: 10px; }
    .history-list { list-style: none; padding-left: 0; }
    .history-list li { margin: 5px 0; }
    .history-list a { text-decoration: none; color: #333; }
    .history-list a:hover { color: #667eea; }
    .footer { text-align: center; font-size: 0.9em; color: #999; padding: 20px; margin-top: 40px; }
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>ğŸ¤– AIèµ„è®¯æ—¥æŠ¥</h1>
      <p>2025/12/3 | äººå·¥æ™ºèƒ½é¢†åŸŸæœ€æ–°åŠ¨æ€</p>
      <div class="nav-buttons">
        <a href="../daily/2025-12-02.html" class="nav-button">
          ğŸ”™ æŸ¥çœ‹æ˜¨æ—¥å†…å®¹
        </a>
        <a href="../" class="nav-button">
          ğŸ  è¿”å›ä¸»é¡µ
        </a>
      </div>
    </div>

    <div class="summary">
      <h2>ğŸ“Š ä»Šæ—¥è¶‹åŠ¿æ€»ç»“</h2>
      <p>ä»Šæ—¥AIèµ„è®¯æ±‡æ€»ï¼ˆè‡ªåŠ¨æ‘˜è¦æš‚æ—¶ä¸å¯ç”¨ï¼‰</p>
    </div>

    <div class="news-grid">
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=35103021" target="_blank">The AI Crackpot Index</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">The AI Crackpot Index</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=27111719" target="_blank">Ask HN: What's the pain using current AI algorithms?</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Ask HN: What's the pain using current AI algorithms?</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=401541" target="_blank">Common Lisp + Machine Learning Internship at Google (Mountain View, CA)</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Common Lisp + Machine Learning Internship at Google (Mountain View, CA)</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=36431356" target="_blank">Ask HN: Anyone concerned about NYC Local Law 144?</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Ask HN: Anyone concerned about NYC Local Law 144?</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=44899994" target="_blank">Ask HN: What would you read to learn about "artificial intelligence"?</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Ask HN: What would you read to learn about "artificial intelligence"?</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=36233487" target="_blank">Ask HN: Is the rate of progress in AI exponential?</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Ask HN: Is the rate of progress in AI exponential?</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=42619160" target="_blank">Show HN: Startup Raising capital through Book Sales</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Show HN: Startup Raising capital through Book Sales</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://www.yourobot.io/blog/uncategorized/the-next-bill-gates-or-albert-einstein-in-ai-artificial-intelligence-will-produce-the-god-algorithm-of-machine-learning-where-a-machine-will-be-able-to-do-and-learn-anything-by-its-self/" target="_blank">The Next Bill Gates or Albert Einstein in AI â€œChris Clarkâ€ â€“ Yourobot</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">The Next Bill Gates or Albert Einstein in AI â€œChris Clarkâ€ â€“ Yourobot</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=44848018" target="_blank">Why Boring Businesses Outlast AI Hype Cycles</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Why Boring Businesses Outlast AI Hype Cycles</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=15140715" target="_blank">Bioinformatician</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Bioinformatician</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://lekta.ai/blog/natural-language-processing-artificial-intelligence-machine-learning-bots-a-passing-trend-or-much-more" target="_blank">NLP, AI, ML, bots â€“ a passing trend or much more? What's your take on this?</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">NLP, AI, ML, bots â€“ a passing trend or much more? What's your take on this?</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=12995049" target="_blank">Ask HN: Dipping my toes with artificial intelligence and what to expect? (CS)</a></h3>
          <div class="news-meta">
            <span class="category industry">è¡Œä¸šåŠ¨æ€</span>
            <span>Hacker News</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Ask HN: Dipping my toes with artificial intelligence and what to expect? (CS)</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2512.03042v1" target="_blank">PPTArena: A Benchmark for Agentic PowerPoint Editing</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">We introduce PPTArena, a benchmark for PowerPoint editing that measures reliable modifications to real slides under natural-language instructions. In contrast to image-PDF renderings or text-to-slide generation, PPTArena focuses on in-place editing across 100 decks, 2125 slides, and over 800 targeted edits covering text, charts, tables, animations, and master-level styles. Each case includes a ground-truth deck, a fully specified target outcome, and a dual VLM-as-judge pipeline that separately scores instruction following and visual quality using both structural diffs and slide images. Building on this setting, we propose PPTPilot, a structure-aware slide-editing agent that plans semantic edit sequences, routes between high-level programmatic tools and deterministic XML operations for precise control, and verifies outputs through an iterative plan-edit-check loop against task-specific constraints. In our experiments, PPTPilot outperforms strong proprietary agents and frontier VLM systems by over 10 percentage points on compound, layout-sensitive, and cross-slide edits, with particularly large gains in visual fidelity and deck-wide consistency. Despite these improvements, existing agents still underperform on long-horizon, document-scale tasks in PPTArena, highlighting the remaining challenges in reliable PPT editing.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2512.03040v1" target="_blank">Video4Spatial: Towards Visuospatial Intelligence with Context-Guided Video Generation</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">We investigate whether video generative models can exhibit visuospatial intelligence, a capability central to human cognition, using only visual data. To this end, we present Video4Spatial, a framework showing that video diffusion models conditioned solely on video-based scene context can perform complex spatial tasks. We validate on two tasks: scene navigation - following camera-pose instructions while remaining consistent with 3D geometry of the scene, and object grounding - which requires semantic localization, instruction following, and planning. Both tasks use video-only inputs, without auxiliary modalities such as depth or poses. With simple yet effective design choices in the framework and data curation, Video4Spatial demonstrates strong spatial understanding from video context: it plans navigation and grounds target objects end-to-end, follows camera-pose instructions while maintaining spatial consistency, and generalizes to long contexts and out-of-domain environments. Taken together, these results advance video generative models toward general visuospatial reasoning.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2512.03036v1" target="_blank">ViSAudio: End-to-End Video-Driven Binaural Spatial Audio Generation</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Despite progress in video-to-audio generation, the field focuses predominantly on mono output, lacking spatial immersion. Existing binaural approaches remain constrained by a two-stage pipeline that first generates mono audio and then performs spatialization, often resulting in error accumulation and spatio-temporal inconsistencies. To address this limitation, we introduce the task of end-to-end binaural spatial audio generation directly from silent video. To support this task, we present the BiAudio dataset, comprising approximately 97K video-binaural audio pairs spanning diverse real-world scenes and camera rotation trajectories, constructed through a semi-automated pipeline. Furthermore, we propose ViSAudio, an end-to-end framework that employs conditional flow matching with a dual-branch audio generation architecture, where two dedicated branches model the audio latent flows. Integrated with a conditional spacetime module, it balances consistency between channels while preserving distinctive spatial characteristics, ensuring precise spatio-temporal alignment between audio and the input video. Comprehensive experiments demonstrate that ViSAudio outperforms existing state-of-the-art methods across both objective metrics and subjective evaluations, generating high-quality binaural audio with spatial immersion that adapts effectively to viewpoint changes, sound-source motion, and diverse acoustic environments. Project website: https://kszpxxzmc.github.io/ViSAudio-project.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2512.03028v1" target="_blank">SMP: Reusable Score-Matching Motion Priors for Physics-Based Character Control</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Data-driven motion priors that can guide agents toward producing naturalistic behaviors play a pivotal role in creating life-like virtual characters. Adversarial imitation learning has been a highly effective method for learning motion priors from reference motion data. However, adversarial priors, with few exceptions, need to be retrained for each new controller, thereby limiting their reusability and necessitating the retention of the reference motion data when training on downstream tasks. In this work, we present Score-Matching Motion Priors (SMP), which leverages pre-trained motion diffusion models and score distillation sampling (SDS) to create reusable task-agnostic motion priors. SMPs can be pre-trained on a motion dataset, independent of any control policy or task. Once trained, SMPs can be kept frozen and reused as general-purpose reward functions to train policies to produce naturalistic behaviors for downstream tasks. We show that a general motion prior trained on large-scale datasets can be repurposed into a variety of style-specific priors. Furthermore SMP can compose different styles to synthesize new styles not present in the original dataset. Our method produces high-quality motion comparable to state-of-the-art adversarial imitation learning methods through reusable and modular motion priors. We demonstrate the effectiveness of SMP across a diverse suite of control tasks with physically simulated humanoid characters. Video demo available at https://youtu.be/ravlZJteS20</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2512.03026v1" target="_blank">The Moral Consistency Pipeline: Continuous Ethical Evaluation for Large Language Models</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">The rapid advancement and adaptability of Large Language Models (LLMs) highlight the need for moral consistency, the capacity to maintain ethically coherent reasoning across varied contexts. Existing alignment frameworks, structured approaches designed to align model behavior with human ethical and social norms, often rely on static datasets and post-hoc evaluations, offering limited insight into how ethical reasoning may evolve across different contexts or temporal scales. This study presents the Moral Consistency Pipeline (MoCoP), a dataset-free, closed-loop framework for continuously evaluating and interpreting the moral stability of LLMs. MoCoP combines three supporting layers: (i) lexical integrity analysis, (ii) semantic risk estimation, and (iii) reasoning-based judgment modeling within a self-sustaining architecture that autonomously generates, evaluates, and refines ethical scenarios without external supervision. Our empirical results on GPT-4-Turbo and DeepSeek suggest that MoCoP effectively captures longitudinal ethical behavior, revealing a strong inverse relationship between ethical and toxicity dimensions (correlation rET = -0.81, p value less than 0.001) and a near-zero association with response latency (correlation rEL approximately equal to 0). These findings demonstrate that moral coherence and linguistic safety tend to emerge as stable and interpretable characteristics of model behavior rather than short-term fluctuations. Furthermore, by reframing ethical evaluation as a dynamic, model-agnostic form of moral introspection, MoCoP offers a reproducible foundation for scalable, continuous auditing and advances the study of computational morality in autonomous AI systems.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2512.03025v1" target="_blank">LORE: A Large Generative Model for Search Relevance</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Achievement. We introduce LORE, a systematic framework for Large Generative Model-based relevance in e-commerce search. Deployed and iterated over three years, LORE achieves a cumulative +27\% improvement in online GoodRate metrics. This report shares the valuable experience gained throughout its development lifecycle, spanning data, features, training, evaluation, and deployment. Insight. While existing works apply Chain-of-Thought (CoT) to enhance relevance, they often hit a performance ceiling. We argue this stems from treating relevance as a monolithic task, lacking principled deconstruction. Our key insight is that relevance comprises distinct capabilities: knowledge and reasoning, multi-modal matching, and rule adherence. We contend that a qualitative-driven decomposition is essential for breaking through current performance bottlenecks. Contributions. LORE provides a complete blueprint for the LLM relevance lifecycle. Key contributions include: (1) A two-stage training paradigm combining progressive CoT synthesis via SFT with human preference alignment via RL. (2) A comprehensive benchmark, RAIR, designed to evaluate these core capabilities. (3) A query frequency-stratified deployment strategy that efficiently transfers offline LLM capabilities to the online system. LORE serves as both a practical solution and a methodological reference for other vertical domains.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2512.03024v1" target="_blank">TokenPowerBench: Benchmarking the Power Consumption of LLM Inference</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Large language model (LLM) services now answer billions of queries per day, and industry reports show that inference, not training, accounts for more than 90% of total power consumption. However, existing benchmarks focus on either training/fine-tuning or performance of inference and provide little support for power consumption measurement and analysis of inference. We introduce TokenPowerBench, the first lightweight and extensible benchmark designed for LLM-inference power consumption studies. The benchmark combines (i) a declarative configuration interface covering model choice, prompt set, and inference engine, (ii) a measurement layer that captures GPU-, node-, and system-level power without specialized power meters, and (iii) a phase-aligned metrics pipeline that attributes energy to the prefill and decode stages of every request. These elements make it straight-forward to explore the power consumed by an LLM inference run; furthermore, by varying batch size, context length, parallelism strategy and quantization, users can quickly assess how each setting affects joules per token and other energy-efficiency metrics. We evaluate TokenPowerBench on four of the most widely used model series (Llama, Falcon, Qwen, and Mistral). Our experiments cover from 1 billion parameters up to the frontier-scale Llama3-405B model. Furthermore, we release TokenPowerBench as open source to help users to measure power consumption, forecast operating expenses, and meet sustainability targets when deploying LLM services.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2512.03019v1" target="_blank">Distribution-Calibrated Inference time compute for Thinking LLM-as-a-Judge</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Thinking Large Language Models (LLMs) used as judges for pairwise preferences remain noisy at the single-sample level, and common aggregation rules (majority vote, soft self-consistency, or instruction-based self-aggregation) are inconsistent when ties are allowed. We study inference-time compute (ITC) for evaluators that generate n independent thinking-rating samples per item, and propose a principled, distribution-calibrated aggregation scheme. Our method models three-way preferences with a Bradley-Terry-Davidson formulation on rating counts, leveraging both polarity (margin among non-ties) and decisiveness (non-tie rate) to distinguish narrow margins from strong consensus. Across various evaluation benchmarks, our approach consistently reduces MAE and increases pairwise accuracy versus standard baselines, and when evaluated against human-consensus meta-labels, matches or exceeds individual human raters. These results show that carefully allocating ITC and aggregating with distribution-aware methods turns noisy individual model judgments into reliable ratings for evaluation.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2512.03013v1" target="_blank">In-Context Sync-LoRA for Portrait Video Editing</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Editing portrait videos is a challenging task that requires flexible yet precise control over a wide range of modifications, such as appearance changes, expression edits, or the addition of objects. The key difficulty lies in preserving the subject's original temporal behavior, demanding that every edited frame remains precisely synchronized with the corresponding source frame. We present Sync-LoRA, a method for editing portrait videos that achieves high-quality visual modifications while maintaining frame-accurate synchronization and identity consistency. Our approach uses an image-to-video diffusion model, where the edit is defined by modifying the first frame and then propagated to the entire sequence. To enable accurate synchronization, we train an in-context LoRA using paired videos that depict identical motion trajectories but differ in appearance. These pairs are automatically generated and curated through a synchronization-based filtering process that selects only the most temporally aligned examples for training. This training setup teaches the model to combine motion cues from the source video with the visual changes introduced in the edited first frame. Trained on a compact, highly curated set of synchronized human portraits, Sync-LoRA generalizes to unseen identities and diverse edits (e.g., modifying appearance, adding objects, or changing backgrounds), robustly handling variations in pose and expression. Our results demonstrate high visual fidelity and strong temporal coherence, achieving a robust balance between edit fidelity and precise motion preservation.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2512.03005v1" target="_blank">From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">The rapid advancement of large language models (LLMs) has opened new possibilities for AI for good applications. As LLMs increasingly mediate online communication, their potential to foster empathy and constructive dialogue becomes an important frontier for responsible AI research. This work explores whether LLMs can serve not only as moderators that detect harmful content, but as mediators capable of understanding and de-escalating online conflicts. Our framework decomposes mediation into two subtasks: judgment, where an LLM evaluates the fairness and emotional dynamics of a conversation, and steering, where it generates empathetic, de-escalatory messages to guide participants toward resolution. To assess mediation quality, we construct a large Reddit-based dataset and propose a multi-stage evaluation pipeline combining principle-based scoring, user simulation, and human comparison. Experiments show that API-based models outperform open-source counterparts in both reasoning and intervention alignment when doing mediation. Our findings highlight both the promise and limitations of current LLMs as emerging agents for online social mediation.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2512.03001v1" target="_blank">Invasive Context Engineering to Control Large Language Models</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Current research on operator control of Large Language Models improves model robustness against adversarial attacks and misbehavior by training on preference examples, prompting, and input/output filtering. Despite good results, LLMs remain susceptible to abuse, and jailbreak probability increases with context length. There is a need for robust LLM security guarantees in long-context situations. We propose control sentences inserted into the LLM context as invasive context engineering to partially solve the problem. We suggest this technique can be generalized to the Chain-of-Thought process to prevent scheming. Invasive Context Engineering does not rely on LLM training, avoiding data shortage pitfalls which arise in training models for long context situations.</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2512.02987v1" target="_blank">Fine-Tuned Large Language Models for Logical Translation: Reducing Hallucinations with Lang2Logic</a></h3>
          <div class="news-meta">
            <span class="category academic">å­¦æœ¯è®ºæ–‡</span>
            <span>ArXiv</span>
            <span class="importance">é‡è¦åº¦: 5</span>
          </div>
          <div class="summary-text">Recent advances in natural language processing (NLP), particularly large language models (LLMs), have motivated the automatic translation of natural language statements into formal logic without human intervention. This enables automated reasoning and facilitates debugging, finding loop invariants, and adhering to specifications in software systems. However, hallucinations-incorrect outputs generated by LLMs are challenging, particularly for logical translation tasks requiring precision. This work introduces a novel framework that inputs English sentences, converts them into logical expressions, and then translates them into Conjunctive Normal Form (CNF) for satisfiability solving. It employs classical NLP techniques with self-defined grammar, symbolic computation libraries, and a fine-tuned language model to reduce hallucinations. In the early experiments, we observed that the fine-tuned model, trained on different grammar settings, could intentionally correct the same types of hallucinations made by the original model. Thus, it provides reliable CNF generation.</div>
          
          
        </div>
      
    </div>

    <div class="history-section">
        <h2>ğŸ“… å†å²æ—¥æŠ¥ç›®å½•</h2>
        <ul class="history-list">
          <li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-02.html" target="_blank">2025-12-02</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-12-01.html" target="_blank">2025-12-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-30.html" target="_blank">2025-11-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-29.html" target="_blank">2025-11-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-28.html" target="_blank">2025-11-28</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-27.html" target="_blank">2025-11-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-26.html" target="_blank">2025-11-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-25.html" target="_blank">2025-11-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-24.html" target="_blank">2025-11-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-23.html" target="_blank">2025-11-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-22.html" target="_blank">2025-11-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-21.html" target="_blank">2025-11-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-20.html" target="_blank">2025-11-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-19.html" target="_blank">2025-11-19</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-18.html" target="_blank">2025-11-18</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-17.html" target="_blank">2025-11-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-16.html" target="_blank">2025-11-16</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-15.html" target="_blank">2025-11-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-14.html" target="_blank">2025-11-14</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-13.html" target="_blank">2025-11-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-12.html" target="_blank">2025-11-12</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-11.html" target="_blank">2025-11-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-10.html" target="_blank">2025-11-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-09.html" target="_blank">2025-11-09</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-08.html" target="_blank">2025-11-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-07.html" target="_blank">2025-11-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-06.html" target="_blank">2025-11-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-05.html" target="_blank">2025-11-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-04.html" target="_blank">2025-11-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-03.html" target="_blank">2025-11-03</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-02.html" target="_blank">2025-11-02</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-11-01.html" target="_blank">2025-11-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-31.html" target="_blank">2025-10-31</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-30.html" target="_blank">2025-10-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-29.html" target="_blank">2025-10-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-28.html" target="_blank">2025-10-28</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-27.html" target="_blank">2025-10-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-26.html" target="_blank">2025-10-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-25.html" target="_blank">2025-10-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-24.html" target="_blank">2025-10-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-23.html" target="_blank">2025-10-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-22.html" target="_blank">2025-10-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-21.html" target="_blank">2025-10-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-20.html" target="_blank">2025-10-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-19.html" target="_blank">2025-10-19</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-18.html" target="_blank">2025-10-18</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-17.html" target="_blank">2025-10-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-16.html" target="_blank">2025-10-16</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-15.html" target="_blank">2025-10-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-14.html" target="_blank">2025-10-14</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-13.html" target="_blank">2025-10-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-12.html" target="_blank">2025-10-12</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-11.html" target="_blank">2025-10-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-10.html" target="_blank">2025-10-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-09.html" target="_blank">2025-10-09</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-08.html" target="_blank">2025-10-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-07.html" target="_blank">2025-10-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-06.html" target="_blank">2025-10-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-05.html" target="_blank">2025-10-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-04.html" target="_blank">2025-10-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-03.html" target="_blank">2025-10-03</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-02.html" target="_blank">2025-10-02</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-01.html" target="_blank">2025-10-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-30.html" target="_blank">2025-09-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-29.html" target="_blank">2025-09-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-28.html" target="_blank">2025-09-28</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-27.html" target="_blank">2025-09-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-26.html" target="_blank">2025-09-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-25.html" target="_blank">2025-09-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-24.html" target="_blank">2025-09-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-23.html" target="_blank">2025-09-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-22.html" target="_blank">2025-09-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-21.html" target="_blank">2025-09-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-20.html" target="_blank">2025-09-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-19.html" target="_blank">2025-09-19</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-18.html" target="_blank">2025-09-18</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-17.html" target="_blank">2025-09-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-16.html" target="_blank">2025-09-16</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-15.html" target="_blank">2025-09-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-14.html" target="_blank">2025-09-14</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-13.html" target="_blank">2025-09-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-12.html" target="_blank">2025-09-12</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-11.html" target="_blank">2025-09-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-10.html" target="_blank">2025-09-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-09.html" target="_blank">2025-09-09</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-08.html" target="_blank">2025-09-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-07.html" target="_blank">2025-09-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-06.html" target="_blank">2025-09-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-05.html" target="_blank">2025-09-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-04.html" target="_blank">2025-09-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-30.html" target="_blank">2025-08-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-25.html" target="_blank">2025-08-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-24.html" target="_blank">2025-08-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-23.html" target="_blank">2025-08-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-22.html" target="_blank">2025-08-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-21.html" target="_blank">2025-08-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-20.html" target="_blank">2025-08-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-17.html" target="_blank">2025-08-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-15.html" target="_blank">2025-08-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-14.html" target="_blank">2025-08-14</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-13.html" target="_blank">2025-08-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-11.html" target="_blank">2025-08-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-10.html" target="_blank">2025-08-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-08.html" target="_blank">2025-08-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-07.html" target="_blank">2025-08-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-06.html" target="_blank">2025-08-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-05.html" target="_blank">2025-08-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-04.html" target="_blank">2025-08-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-03.html" target="_blank">2025-08-03</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-02.html" target="_blank">2025-08-02</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-01.html" target="_blank">2025-08-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-31.html" target="_blank">2025-07-31</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-30.html" target="_blank">2025-07-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-29.html" target="_blank">2025-07-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-27.html" target="_blank">2025-07-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-26.html" target="_blank">2025-07-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-25.html" target="_blank">2025-07-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-24.html" target="_blank">2025-07-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-23.html" target="_blank">2025-07-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-22.html" target="_blank">2025-07-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-21.html" target="_blank">2025-07-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-20.html" target="_blank">2025-07-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-19.html" target="_blank">2025-07-19</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-18.html" target="_blank">2025-07-18</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-17.html" target="_blank">2025-07-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-16.html" target="_blank">2025-07-16</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-15.html" target="_blank">2025-07-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-13.html" target="_blank">2025-07-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-12.html" target="_blank">2025-07-12</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-11.html" target="_blank">2025-07-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-10.html" target="_blank">2025-07-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-09.html" target="_blank">2025-07-09</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-08.html" target="_blank">2025-07-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-07.html" target="_blank">2025-07-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-06.html" target="_blank">2025-07-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-05.html" target="_blank">2025-07-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-04.html" target="_blank">2025-07-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-03.html" target="_blank">2025-07-03</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-02.html" target="_blank">2025-07-02</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-01.html" target="_blank">2025-07-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-30.html" target="_blank">2025-06-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-29.html" target="_blank">2025-06-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-28.html" target="_blank">2025-06-28</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-27.html" target="_blank">2025-06-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-26.html" target="_blank">2025-06-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-25.html" target="_blank">2025-06-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-24.html" target="_blank">2025-06-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-23.html" target="_blank">2025-06-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-22.html" target="_blank">2025-06-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-21.html" target="_blank">2025-06-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-20.html" target="_blank">2025-06-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-19.html" target="_blank">2025-06-19</a></li>
        </ul>
      </div>

    <div class="footer">
      ğŸ”„ ç”± Cloudflare Workers + DeepSeek è‡ªåŠ¨ç”Ÿæˆ | æ›´æ–°æ—¶é—´: 2025/12/3 22:02:14
    </div>
  </div>
</body>
</html>