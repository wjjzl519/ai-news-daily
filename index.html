<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>AI资讯日报 - 2025/10/24</title>
  <style>
    /* 添加按钮样式 */
    .nav-buttons {
      display: flex;
      gap: 15px;
      justify-content: center;
      margin-top: 15px;
      flex-wrap: wrap;
    }
    .nav-button {
      background: rgba(255, 255, 255, 0.2);
      border: 1px solid rgba(255, 255, 255, 0.4);
      border-radius: 20px;
      padding: 6px 15px;
      color: white;
      text-decoration: none;
      display: inline-flex;
      align-items: center;
      transition: all 0.3s;
      font-size: 0.9em;
    }
    .nav-button:hover {
      background: rgba(255, 255, 255, 0.3);
      transform: translateY(-2px);
    }
    /* 其他样式保持不变 */
    body { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; background: #f5f5f5; color: #333; margin: 0; padding: 0; }
    .container { max-width: 1200px; margin: auto; padding: 20px; }
    .header { background: linear-gradient(135deg, #667eea, #764ba2); color: #fff; padding: 40px 20px; border-radius: 10px; text-align: center; }
    .header h1 { font-size: 2.5em; margin: 0; }
    .summary, .history-section { background: #fff; margin-top: 30px; padding: 25px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
    .summary h2, .history-section h2 { color: #667eea; border-bottom: 1px solid #eee; padding-bottom: 10px; margin-bottom: 15px; }
    .news-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(350px, 1fr)); gap: 20px; margin-top: 30px; }
    .news-item { background: white; border-radius: 10px; padding: 20px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }
    .news-item h3 a { text-decoration: none; color: #333; font-size: 1.1em; }
    .news-item h3 a:hover { color: #667eea; }
    .news-meta { font-size: 0.9em; color: #666; margin-bottom: 10px; }
    .category { display: inline-block; padding: 4px 10px; border-radius: 20px; font-size: 0.8em; margin-right: 8px; }
    .category.industry { background: #e3f2fd; color: #1976d2; }
    .category.academic { background: #f3e5f5; color: #7b1fa2; }
    .category.opensource { background: #e8f5e9; color: #388e3c; }
    .summary-text { margin-top: 10px; color: #555; }
    .importance { background: #ff9800; color: white; padding: 2px 8px; border-radius: 10px; font-size: 0.75em; margin-left: 10px; }
    .history-list { list-style: none; padding-left: 0; }
    .history-list li { margin: 5px 0; }
    .history-list a { text-decoration: none; color: #333; }
    .history-list a:hover { color: #667eea; }
    .footer { text-align: center; font-size: 0.9em; color: #999; padding: 20px; margin-top: 40px; }
  </style>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>🤖 AI资讯日报</h1>
      <p>2025/10/24 | 人工智能领域最新动态</p>
      <div class="nav-buttons">
        <a href="../daily/2025-10-23.html" class="nav-button">
          🔙 查看昨日内容
        </a>
        <a href="../" class="nav-button">
          🏠 返回主页
        </a>
      </div>
    </div>

    <div class="summary">
      <h2>📊 今日趋势总结</h2>
      <p>这些资讯反映了AI行业的多元关注点：从技术发展速度的讨论（指数级增长疑问）、实际应用痛点（算法使用问题），到行业泡沫担忧（AI Crackpot Index、炒作周期警示）。同时包含学习资源需求、职业机会（Google实习、生物信息学岗位），以及监管影响（纽约地方法律）和创业融资创新方式。整体显示AI领域正处于技术探索、商业应用和行业规范并行的阶段，既有对技术潜力的期待，也有对现实挑战的理性思考。</p>
    </div>

    <div class="news-grid">
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=44848018" target="_blank">Why Boring Businesses Outlast AI Hype Cycles</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 9</span>
          </div>
          <div class="summary-text">探讨务实企业如何在AI炒作周期中持久发展</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=27111719" target="_blank">Ask HN: What's the pain using current AI algorithms?</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 8</span>
          </div>
          <div class="summary-text">讨论当前AI算法使用中的痛点和挑战</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=36233487" target="_blank">Ask HN: Is the rate of progress in AI exponential?</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 8</span>
          </div>
          <div class="summary-text">探讨AI发展速度是否呈指数级增长</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=35103021" target="_blank">The AI Crackpot Index</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 7</span>
          </div>
          <div class="summary-text">AI领域不靠谱言论索引，识别行业泡沫</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://lekta.ai/blog/natural-language-processing-artificial-intelligence-machine-learning-bots-a-passing-trend-or-much-more" target="_blank">NLP, AI, ML, bots – a passing trend or much more? What's your take on this?</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 7</span>
          </div>
          <div class="summary-text">NLP, AI, ML, bots – a passing trend or much more? What's your take on this?</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=36431356" target="_blank">Ask HN: Anyone concerned about NYC Local Law 144?</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 7</span>
          </div>
          <div class="summary-text">讨论纽约地方法律144对AI行业的影响和担忧</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=401541" target="_blank">Common Lisp + Machine Learning Internship at Google (Mountain View, CA)</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 6</span>
          </div>
          <div class="summary-text">谷歌Common Lisp与机器学习实习机会</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=44899994" target="_blank">Ask HN: What would you read to learn about "artificial intelligence"?</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 6</span>
          </div>
          <div class="summary-text">寻求AI学习资源推荐</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=12995049" target="_blank">Ask HN: Dipping my toes with artificial intelligence and what to expect? (CS)</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 6</span>
          </div>
          <div class="summary-text">计算机科学背景初学者询问AI入门预期</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=15140715" target="_blank">Bioinformatician</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 5</span>
          </div>
          <div class="summary-text">生物信息学职位机会</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="https://news.ycombinator.com/item?id=42619160" target="_blank">Show HN: Startup Raising capital through Book Sales</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 4</span>
          </div>
          <div class="summary-text">初创公司通过图书销售筹集资金</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://www.yourobot.io/blog/uncategorized/the-next-bill-gates-or-albert-einstein-in-ai-artificial-intelligence-will-produce-the-god-algorithm-of-machine-learning-where-a-machine-will-be-able-to-do-and-learn-anything-by-its-self/" target="_blank">The Next Bill Gates or Albert Einstein in AI "Chris Clark" – Yourobot</a></h3>
          <div class="news-meta">
            <span class="category industry">行业动态</span>
            <span>Hacker News</span>
            <span class="importance">重要度: 3</span>
          </div>
          <div class="summary-text">介绍AI领域的潜在领军人物Chris Clark</div>
          
          
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2510.20819v1" target="_blank">Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 9</span>
          </div>
          <div class="summary-text">提出潜在去噪扩散桥模型，实现任意模态间转换，无需对齐维度，在多种跨模态任务中表现优异。</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Nimrod Berman, Omkar Joglekar, Eitan Kosman, Dotan Di Castro, Omri Azencot</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2510.20818v1" target="_blank">VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 8</span>
          </div>
          <div class="summary-text">A fundamental challenge in robot navigation lies in learning policies that
generalize across diverse environments while conforming to the unique physical
constraints and capabilities of a specific embodiment (e.g., quadrupeds can
walk up stairs, but rovers cannot). We propose VAMOS, a hierarchical VLA that
decouples semantic planning from embodiment grounding: a generalist planner
learns from diverse, open-world data, while a specialist affordance model
learns the robot's physical constraints and capabilities in safe, low-cost
simulation. We enabled this separation by carefully designing an interface that
lets a high-level planner propose candidate paths directly in image space that
the affordance model then evaluates and re-ranks. Our real-world experiments
show that VAMOS achieves higher success rates in both indoor and complex
outdoor navigation than state-of-the-art model-based and end-to-end learning
methods. We also show that our hierarchical design enables cross-embodied
navigation across legged and wheeled robots and is easily steerable using
natural language. Real-world ablations confirm that the specialist model is key
to embodiment grounding, enabling a single high-level planner to be deployed
across physically distinct wheeled and legged robots. Finally, this model
significantly enhances single-robot reliability, achieving 3X higher success
rates by rejecting physically infeasible plans. Website:
https://vamos-vla.github.io/</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Mateo Guaman Castro, Sidharth Rajagopal, Daniel Gorbatov, Matt Schmittle, Rohan Baijal, Octi Zhang, Rosario Scalise, Sidharth Talia, Emma Romig, Celso de Melo, Byron Boots, Abhishek Gupta</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2510.20813v1" target="_blank">GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 8</span>
          </div>
          <div class="summary-text">This paper presents GSWorld, a robust, photo-realistic simulator for robotics
manipulation that combines 3D Gaussian Splatting with physics engines. Our
framework advocates "closing the loop" of developing manipulation policies with
reproducible evaluation of policies learned from real-robot data and sim2real
policy training without using real robots. To enable photo-realistic rendering
of diverse scenes, we propose a new asset format, which we term GSDF (Gaussian
Scene Description File), that infuses Gaussian-on-Mesh representation with
robot URDF and other objects. With a streamlined reconstruction pipeline, we
curate a database of GSDF that contains 3 robot embodiments for single-arm and
bimanual manipulation, as well as more than 40 objects. Combining GSDF with
physics engines, we demonstrate several immediate interesting applications: (1)
learning zero-shot sim2real pixel-to-action manipulation policy with
photo-realistic rendering, (2) automated high-quality DAgger data collection
for adapting policies to deployment environments, (3) reproducible benchmarking
of real-robot manipulation policies in simulation, (4) simulation data
collection by virtual teleoperation, and (5) zero-shot sim2real visual
reinforcement learning. Website: https://3dgsworld.github.io/.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Guangqi Jiang, Haoran Chang, Ri-Zhao Qiu, Yutong Liang, Mazeyu Ji, Jiyue Zhu, Zhao Dong, Xueyan Zou, Xiaolong Wang</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2510.20812v1" target="_blank">Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 7</span>
          </div>
          <div class="summary-text">Large Vision-Language Models (VLMs) have achieved remarkable progress in
multimodal understanding, yet they struggle when reasoning over
information-intensive images that densely interleave textual annotations with
fine-grained graphical elements. The main challenges lie in precisely
localizing critical cues in dense layouts and multi-hop reasoning to integrate
dispersed evidence. We propose Speculative Verdict (SV), a training-free
framework inspired by speculative decoding that combines multiple lightweight
draft experts with a large verdict model. In the draft stage, small VLMs act as
draft experts to generate reasoning paths that provide diverse localization
candidates; in the verdict stage, a strong VLM synthesizes these paths to
produce the final answer, minimizing computational cost while recovering
correct answers. To further improve efficiency and accuracy, SV introduces a
consensus expert selection mechanism that forwards only high-agreement
reasoning paths to the verdict. Empirically, SV achieves consistent gains on
challenging information-intensive and high-resolution visual question answering
benchmarks, including InfographicVQA, ChartMuseum, ChartQAPro, and HR-Bench 4K.
By synthesizing correct insights from multiple partially accurate reasoning
paths, SV achieves both error correction and cost-efficiency compared to large
proprietary models or training pipelines. Code is available at
https://github.com/Tinaliu0123/speculative-verdict</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Yuhan Liu, Lianhui Qin, Shengjie Wang</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2510.20808v1" target="_blank">The Reality Gap in Robotics: Challenges, Solutions, and Best Practices</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 7</span>
          </div>
          <div class="summary-text">Machine learning has facilitated significant advancements across various
robotics domains, including navigation, locomotion, and manipulation. Many such
achievements have been driven by the extensive use of simulation as a critical
tool for training and testing robotic systems prior to their deployment in
real-world environments. However, simulations consist of abstractions and
approximations that inevitably introduce discrepancies between simulated and
real environments, known as the reality gap. These discrepancies significantly
hinder the successful transfer of systems from simulation to the real world.
Closing this gap remains one of the most pressing challenges in robotics.
Recent advances in sim-to-real transfer have demonstrated promising results
across various platforms, including locomotion, navigation, and manipulation.
By leveraging techniques such as domain randomization, real-to-sim transfer,
state and action abstractions, and sim-real co-training, many works have
overcome the reality gap. However, challenges persist, and a deeper
understanding of the reality gap's root causes and solutions is necessary. In
this survey, we present a comprehensive overview of the sim-to-real landscape,
highlighting the causes, solutions, and evaluation metrics for the reality gap
and sim-to-real transfer.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Elie Aljalbout, Jiaxu Xing, Angel Romero, Iretiayo Akinola, Caelan Reed Garrett, Eric Heiden, Abhishek Gupta, Tucker Hermans, Yashraj Narang, Dieter Fox, Davide Scaramuzza, Fabio Ramos</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2510.20800v1" target="_blank">Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 7</span>
          </div>
          <div class="summary-text">Recently, Sharma et al. suggested a method called Layer-SElective-Rank
reduction (LASER) which demonstrated that pruning high-order components of
carefully chosen LLM's weight matrices can boost downstream accuracy -- without
any gradient-based fine-tuning. Yet LASER's exhaustive, per-matrix search (each
requiring full-dataset forward passes) makes it impractical for rapid
deployment. We demonstrate that this overhead can be removed and find that: (i)
Only a small, carefully chosen subset of matrices needs to be inspected --
eliminating the layer-by-layer sweep, (ii) The gradient of each matrix's
singular values pinpoints which matrices merit reduction, (iii) Increasing the
factorization search space by allowing matrices rows to cluster around multiple
subspaces and then decomposing each cluster separately further reduces
overfitting on the original training data and further lifts accuracy by up to
24.6 percentage points, and finally, (iv) we discover that evaluating on just
100 samples rather than the full training data -- both for computing the
indicative gradients and for measuring the final accuracy -- suffices to
further reduce the search time; we explain that as adaptation to downstream
tasks is dominated by prompting style, not dataset size. As a result, we show
that combining these findings yields a fast and robust adaptation algorithm for
downstream tasks. Overall, with a single gradient step on 100 examples and a
quick scan of the top candidate layers and factorization techniques, we can
adapt LLMs to new datasets -- entirely without fine-tuning.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Shiva Sreeram, Alaa Maalouf, Pratyusha Sharma, Daniela Rus</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2510.20784v1" target="_blank">A Coherence-Based Measure of AGI</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 7</span>
          </div>
          <div class="summary-text">Recent work by \citet{hendrycks2025agidefinition} formalized
\textit{Artificial General Intelligence} (AGI) as the arithmetic mean of
proficiencies across cognitive domains derived from the Cattell--Horn--Carroll
(CHC) model of human cognition. While elegant, this definition assumes
\textit{compensability} -- that exceptional ability in some domains can offset
failure in others. True general intelligence, however, should reflect
\textit{coherent sufficiency}: balanced competence across all essential
domains. We propose a coherence-aware measure of AGI based on the integral of
generalized means over a continuum of compensability exponents. This
formulation spans arithmetic, geometric, and harmonic regimes, and the
resulting \textit{area under the curve} (AUC) quantifies robustness under
varying compensability assumptions. Unlike the arithmetic mean, which rewards
specialization, the AUC penalizes imbalance and captures inter-domain
dependency. Applied to published CHC-based domain scores for GPT-4 and GPT-5,
the coherence-adjusted AUC reveals that both systems remain far from general
competence despite high arithmetic scores (e.g., GPT-5 at~24\%). Integrating
the generalized mean thus yields a principled, interpretable, and stricter
foundation for measuring genuine progress toward AGI.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Fares Fourati</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2510.20810v1" target="_blank">On the Detectability of LLM-Generated Text: What Exactly Is LLM-Generated Text?</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 6</span>
          </div>
          <div class="summary-text">With the widespread use of large language models (LLMs), many researchers
have turned their attention to detecting text generated by them. However, there
is no consistent or precise definition of their target, namely "LLM-generated
text". Differences in usage scenarios and the diversity of LLMs further
increase the difficulty of detection. What is commonly regarded as the
detecting target usually represents only a subset of the text that LLMs can
potentially produce. Human edits to LLM outputs, together with the subtle
influences that LLMs exert on their users, are blurring the line between
LLM-generated and human-written text. Existing benchmarks and evaluation
approaches do not adequately address the various conditions in real-world
detector applications. Hence, the numerical results of detectors are often
misunderstood, and their significance is diminishing. Therefore, detectors
remain useful under specific conditions, but their results should be
interpreted only as references rather than decisive indicators.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Mingmeng Geng, Thierry Poibeau</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2510.20809v1" target="_blank">Real Deep Research for AI, Robotics and Beyond</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 6</span>
          </div>
          <div class="summary-text">With the rapid growth of research in AI and robotics now producing over
10,000 papers annually it has become increasingly difficult for researchers to
stay up to date. Fast evolving trends, the rise of interdisciplinary work, and
the need to explore domains beyond one's expertise all contribute to this
challenge. To address these issues, we propose a generalizable pipeline capable
of systematically analyzing any research area: identifying emerging trends,
uncovering cross domain opportunities, and offering concrete starting points
for new inquiry. In this work, we present Real Deep Research (RDR) a
comprehensive framework applied to the domains of AI and robotics, with a
particular focus on foundation models and robotics advancements. We also
briefly extend our analysis to other areas of science. The main paper details
the construction of the RDR pipeline, while the appendix provides extensive
results across each analyzed topic. We hope this work sheds light for
researchers working in the field of AI and beyond.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Xueyan Zou, Jianglong Ye, Hao Zhang, Xiaoyu Xiang, Mingyu Ding, Zhaojing Yang, Yong Jae Lee, Zhuowen Tu, Sifei Liu, Xiaolong Wang</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2510.20797v1" target="_blank">Simple Context Compression: Mean-Pooling and Multi-Ratio Training</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 6</span>
          </div>
          <div class="summary-text">A common strategy to reduce the computational costs of using long contexts in
retrieval-augmented generation (RAG) with large language models (LLMs) is soft
context compression, where the input sequence is transformed into a shorter
continuous representation. We develop a lightweight and simple mean-pooling
approach that consistently outperforms the widely used compression-tokens
architecture, and study training the same compressor to output multiple
compression ratios. We conduct extensive experiments across in-domain and
out-of-domain QA datasets, as well as across model families, scales, and
compression ratios. Overall, our simple mean-pooling approach achieves the
strongest performance, with a relatively small drop when training for multiple
compression ratios. More broadly though, across architectures and training
regimes the trade-offs are more nuanced, illustrating the complex landscape of
compression methods.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Yair Feldman, Yoav Artzi</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2510.20795v1" target="_blank">Bayesian Inference of Primordial Magnetic Field Parameters from CMB with Spherical Graph Neural Networks</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 5</span>
          </div>
          <div class="summary-text">Deep learning has emerged as a transformative methodology in modern
cosmology, providing powerful tools to extract meaningful physical information
from complex astronomical datasets. This paper implements a novel Bayesian
graph deep learning framework for estimating key cosmological parameters in a
primordial magnetic field (PMF) cosmology directly from simulated Cosmic
Microwave Background (CMB) maps. Our methodology utilizes DeepSphere, a
spherical convolutional neural network architecture specifically designed to
respect the spherical geometry of CMB data through HEALPix pixelization. To
advance beyond deterministic point estimates and enable robust uncertainty
quantification, we integrate Bayesian Neural Networks (BNNs) into the
framework, capturing aleatoric and epistemic uncertainties that reflect the
model confidence in its predictions. The proposed approach demonstrates
exceptional performance, achieving $R^{2}$ scores exceeding 0.89 for the
magnetic parameter estimation. We further obtain well-calibrated uncertainty
estimates through post-hoc training techniques including Variance Scaling and
GPNormal. This integrated DeepSphere-BNNs framework not only delivers accurate
parameter estimation from CMB maps with PMF contributions but also provides
reliable uncertainty quantification, providing the necessary tools for robust
cosmological inference in the era of precision cosmology.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Juan Alejandro Pinto Castro, Héctor J. Hortúa, Jorge Enrique García-Farieta, Roger Anderson Hurtado</div>
        </div>
      
        <div class="news-item">
          <h3><a href="http://arxiv.org/abs/2510.20782v1" target="_blank">A Use-Case Specific Dataset for Measuring Dimensions of Responsible Performance in LLM-generated Text</a></h3>
          <div class="news-meta">
            <span class="category academic">学术论文</span>
            <span>ArXiv</span>
            <span class="importance">重要度: 5</span>
          </div>
          <div class="summary-text">Current methods for evaluating large language models (LLMs) typically focus
on high-level tasks such as text generation, without targeting a particular AI
application. This approach is not sufficient for evaluating LLMs for
Responsible AI dimensions like fairness, since protected attributes that are
highly relevant in one application may be less relevant in another. In this
work, we construct a dataset that is driven by a real-world application
(generate a plain-text product description, given a list of product features),
parameterized by fairness attributes intersected with gendered adjectives and
product categories, yielding a rich set of labeled prompts. We show how to use
the data to identify quality, veracity, safety, and fairness gaps in LLMs,
contributing a proposal for LLM evaluation paired with a concrete resource for
the research community.</div>
          
          <div style="margin-top:5px; font-size:0.9em; color:#666;">👨‍🔬 Alicia Sagae, Chia-Jung Lee, Sandeep Avula, Brandon Dang, Vanessa Murdock</div>
        </div>
      
    </div>

    <div class="history-section">
        <h2>📅 历史日报目录</h2>
        <ul class="history-list">
          <li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-23.html" target="_blank">2025-10-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-22.html" target="_blank">2025-10-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-21.html" target="_blank">2025-10-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-20.html" target="_blank">2025-10-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-19.html" target="_blank">2025-10-19</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-18.html" target="_blank">2025-10-18</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-17.html" target="_blank">2025-10-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-16.html" target="_blank">2025-10-16</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-15.html" target="_blank">2025-10-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-14.html" target="_blank">2025-10-14</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-13.html" target="_blank">2025-10-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-12.html" target="_blank">2025-10-12</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-11.html" target="_blank">2025-10-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-10.html" target="_blank">2025-10-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-09.html" target="_blank">2025-10-09</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-08.html" target="_blank">2025-10-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-07.html" target="_blank">2025-10-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-06.html" target="_blank">2025-10-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-05.html" target="_blank">2025-10-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-04.html" target="_blank">2025-10-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-03.html" target="_blank">2025-10-03</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-02.html" target="_blank">2025-10-02</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-10-01.html" target="_blank">2025-10-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-30.html" target="_blank">2025-09-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-29.html" target="_blank">2025-09-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-28.html" target="_blank">2025-09-28</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-27.html" target="_blank">2025-09-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-26.html" target="_blank">2025-09-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-25.html" target="_blank">2025-09-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-24.html" target="_blank">2025-09-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-23.html" target="_blank">2025-09-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-22.html" target="_blank">2025-09-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-21.html" target="_blank">2025-09-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-20.html" target="_blank">2025-09-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-19.html" target="_blank">2025-09-19</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-18.html" target="_blank">2025-09-18</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-17.html" target="_blank">2025-09-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-16.html" target="_blank">2025-09-16</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-15.html" target="_blank">2025-09-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-14.html" target="_blank">2025-09-14</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-13.html" target="_blank">2025-09-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-12.html" target="_blank">2025-09-12</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-11.html" target="_blank">2025-09-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-10.html" target="_blank">2025-09-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-09.html" target="_blank">2025-09-09</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-08.html" target="_blank">2025-09-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-07.html" target="_blank">2025-09-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-06.html" target="_blank">2025-09-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-05.html" target="_blank">2025-09-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-09-04.html" target="_blank">2025-09-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-30.html" target="_blank">2025-08-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-25.html" target="_blank">2025-08-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-24.html" target="_blank">2025-08-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-23.html" target="_blank">2025-08-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-22.html" target="_blank">2025-08-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-21.html" target="_blank">2025-08-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-20.html" target="_blank">2025-08-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-17.html" target="_blank">2025-08-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-15.html" target="_blank">2025-08-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-14.html" target="_blank">2025-08-14</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-13.html" target="_blank">2025-08-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-11.html" target="_blank">2025-08-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-10.html" target="_blank">2025-08-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-08.html" target="_blank">2025-08-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-07.html" target="_blank">2025-08-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-06.html" target="_blank">2025-08-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-05.html" target="_blank">2025-08-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-04.html" target="_blank">2025-08-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-03.html" target="_blank">2025-08-03</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-02.html" target="_blank">2025-08-02</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-08-01.html" target="_blank">2025-08-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-31.html" target="_blank">2025-07-31</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-30.html" target="_blank">2025-07-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-29.html" target="_blank">2025-07-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-27.html" target="_blank">2025-07-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-26.html" target="_blank">2025-07-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-25.html" target="_blank">2025-07-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-24.html" target="_blank">2025-07-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-23.html" target="_blank">2025-07-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-22.html" target="_blank">2025-07-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-21.html" target="_blank">2025-07-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-20.html" target="_blank">2025-07-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-19.html" target="_blank">2025-07-19</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-18.html" target="_blank">2025-07-18</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-17.html" target="_blank">2025-07-17</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-16.html" target="_blank">2025-07-16</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-15.html" target="_blank">2025-07-15</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-13.html" target="_blank">2025-07-13</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-12.html" target="_blank">2025-07-12</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-11.html" target="_blank">2025-07-11</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-10.html" target="_blank">2025-07-10</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-09.html" target="_blank">2025-07-09</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-08.html" target="_blank">2025-07-08</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-07.html" target="_blank">2025-07-07</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-06.html" target="_blank">2025-07-06</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-05.html" target="_blank">2025-07-05</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-04.html" target="_blank">2025-07-04</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-03.html" target="_blank">2025-07-03</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-02.html" target="_blank">2025-07-02</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-07-01.html" target="_blank">2025-07-01</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-30.html" target="_blank">2025-06-30</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-29.html" target="_blank">2025-06-29</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-28.html" target="_blank">2025-06-28</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-27.html" target="_blank">2025-06-27</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-26.html" target="_blank">2025-06-26</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-25.html" target="_blank">2025-06-25</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-24.html" target="_blank">2025-06-24</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-23.html" target="_blank">2025-06-23</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-22.html" target="_blank">2025-06-22</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-21.html" target="_blank">2025-06-21</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-20.html" target="_blank">2025-06-20</a></li><li><a href="https://wjjzl519.github.io/ai-news-daily/daily/2025-06-19.html" target="_blank">2025-06-19</a></li>
        </ul>
      </div>

    <div class="footer">
      🔄 由 Cloudflare Workers + DeepSeek 自动生成 | 更新时间: 2025/10/24 22:01:57
    </div>
  </div>
</body>
</html>